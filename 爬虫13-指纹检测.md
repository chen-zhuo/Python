# 指纹检测

指纹，这个很好理解，就是手指的纹路，每个人都有且独一无二，现实生活中很多案件都是靠嫌疑人的指纹破案的。**在写爬虫的时候，觉得只要自己每次请求都使用不同的代理 IP，每次请求的 Headers 都写得跟浏览器的一模一样，就不会被网站发现，但实际上还有一个东西，也叫做指纹。**

**这里的指纹，我们可以理解为一串带有特征字符的字符串。**ja3指纹查看网址：https://ja3er.com/json，该网址会返回3个字段分别为：

```
"ja3_hash":ja3指纹哈希
"ja3":ja3指纹
"User-Agent":用户代理头
```

## 浏览器指纹

首先，**每种浏览器都有自己的指纹**，注意是**每种**，**也就意味着相同的浏览器的指纹是一样的**。

相同浏览器不同版本：**可以看到同样都是Chrome浏览器，一个92版本，一个96版本，但是他们访问，返回的指纹和哈希都是一样。**

![QQ截图20211210171139](image/QQ截图20211210171139.png)

不同浏览器：**可以看不同浏览器的指纹和哈希都是不一样的。**

![QQ截图20211210172014](image/QQ截图20211210172014.png)

## 爬虫指纹

**不仅浏览器有指纹，其实爬虫也有指纹，和浏览器类似，爬虫的指纹也不是唯一的。**

### 指纹测试

在不改变请求头的情况下访问该站点：**可以看到爬虫指纹没有发生变化。**

```python
import requests

res = requests.get('https://ja3er.com/json')
print((res.json()).get("ja3_hash"))

res = requests.get('https://ja3er.com/json')
print((res.json()).get("ja3_hash"))

'''
输出：
3e185b41c1418c77e11390421fca3512
3e185b41c1418c77e11390421fca3512
'''
```

在改变请求头的情况下访问该站点：**可以看到爬虫指纹没有发生变化。**

```python
import requests

headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36"}
res = requests.get('https://ja3er.com/json', headers=headers)
print((res.json()).get("ja3_hash"))

headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.55 Safari/537.36 Edg/96.0.1054.43"}
res = requests.get('https://ja3er.com/json', headers=headers)
print((res.json()).get("ja3_hash"))

'''
输出：
3e185b41c1418c77e11390421fca3512
3e185b41c1418c77e11390421fca3512
'''
```

在使用代理的情况下访问该站点：**可以看到爬虫指纹没有发生变化。**

```python
import requests

proxies = {
    "http": "http://598020642:je3fy3ei@1.56.45.236:15977",
    "https": "https://598020642:je3fy3ei@1.56.45.236:15977"
}
res = requests.get('https://ja3er.com/json', proxies=proxies)
print((res.json()).get("ja3_hash"))

proxies = {
    "http": "http://598020642:je3fy3ei@106.116.65.132:20456",
    "https": "https://598020642:je3fy3ei@106.116.65.132:20456"
}
res = requests.get('https://ja3er.com/json', proxies=proxies)
print((res.json()).get("ja3_hash"))

'''
输出：
3e185b41c1418c77e11390421fca3512
3e185b41c1418c77e11390421fca3512
'''
```

在使用不同库的情况下访问该站点：**可以看到爬虫指纹发生变化。**

```python
import httpx
import requests

res = requests.get('https://ja3er.com/json')
print((res.json()).get("ja3_hash"))

res = httpx.get('https://ja3er.com/json')
print((res.json()).get("ja3_hash"))

'''
输出：
3e185b41c1418c77e11390421fca3512
f320b573a00b0a6ab6f3005486004da9
'''
```

这里可以得出一个结论就是：爬虫的指纹是不会随着你更换 IP 或者 User-Agent 而改变的，，，它们也有自己各自的指纹，但他们的指纹每次请求也是固定的，只要网站发现某个拥有特定指纹的客户端持续高频率请求网站，它就可以把你封掉，你如果不相信，那我证明给你看。



