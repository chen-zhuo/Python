# JS加密

目前，我们已经能爬取普通网页和含有Ajax网页的数据了，但这两类网页并不能代表所有的网页，还有一类网页很不好“对付”了，那个就是含有Js加密的网页了。

### 了解Js

##### Js简介

**Js：全称 JavaScript，是一种运行在浏览器里面的前端语言。**

JavaScript 名称中虽然含有 Java，但和 Java 的关系类似于“北大”和“北大青鸟”，没有半毛关系。

##### Js作用

JavaScript作用：及时响应用户的操作，实现网页特效，增加网页互动性。

JavaScript应用场景：鼠标滑过弹出下拉菜单、新闻图片的轮换等。

### 加密反爬

##### Js加密

Js还有一个功能就是：**可以对一些前端参数进行加密，以便服务器后台便于验证**。如对用户名和密码进行加密，后端可以判断是否是正确的请求还是恶意的攻击。

**Js加密一般是在请求头或者请求参数中加入加密字段，即加密大多出现在表单提交过程中。**

##### 加密cookie

使用Js加密cookie就可以区别是浏览器正确的请求还是使用诸如Httpclient等框架在爬取网页内容了，所以就可以防止别人爬取网站里面的内容。

![20190120142936282](image/20190120142936282.png)

##### 加密算法

上面提到 JS是运行在浏览器里面的，**也就是说加密的过程一定是在浏览器完成，也就是一定会把JS代码暴露给使用者，但是有的公司，为了防止被竞争对手抓取或使用自己的代码，就会对JS混淆加密，来达到代码保护。**

**常见的加密算法**：MD5加密（**不可逆**，生成32位字符串）、Base64加密（**可逆**）、shal加密。

##### Js反爬过程

普通的爬虫只是负责拿着你给的URL传递一些参数来获取网页源码，它们不能运行Js，也就无法对服务器需要验证的参数进行加密，从而导致服务器拒绝你的请求，给你返回一个不是你所期望的网页内容的页面，Js也就完成了一次反爬。

### 破解Js加密

面对Js反爬，爬虫就认输了吗？NO！所谓魔高一尺道高一丈，有反爬虫，就有反反爬虫技术。

##### 破解方法

方法一：把Js代码翻译成Python代码。这个是有难度的，因为爬虫偏向于后端的处理，Js属于前端，需要精通前端才行，还有一点就是经过加密，混要，压缩的js代码阅读性很差。(技术要求高，不建议)

方法二： 执行js代码。使用Python的一些第三方库比如 pyv8库、execjs库去执行js代码。(建议)

方法三：使用selenium或者appiun等框架，驱动浏览器抓取数据，无视js加密。(效率低，稳定性差，不是很建议)

这里我们用第二种方法来破解。

##### Node.js

执行js代码，首先需要一个能执行Js的环境，这里推荐安装Node.js。

**Node.js** ：一个基于 Chrome V8 引擎的 **JavaScript 运行环境**，下载地址：https://nodejs.org/en/download/。

将下载的文件解压到自定义的位置，拷贝解压路径，添加到环境变量中。检测PATH环境变量是否配置了Node.js，命令行中输入：`node --version` 命令，检查Node.js版本。

![QQ截图20200323224413](image/QQ截图20200323224413.png)

##### PyExecJS

安装好了Js的运行环境，接下来我们安装一个第三方库PyExecJS：

```
pip install -i https://pypi.douban.com/simple PyExecJS
```

**PyExecJS 是一个可以使用 Python 来模拟运行 JavaScript 的库。**大家可能听说过 PyV8，它也是用来模拟执行 JavaScript 的库，可是由于这个项目已经不维护了，而且对 Python3 的支持不好，而且安装出现各种问题，所以这里选用了 PyExecJS 库。

运行代码检查一下运行环境：

```python
# 注意：在导入的时候是execjs不是PyExecJS
import execjs
print(execjs.get().name)

'''
# 解释：js运行环境为Node.js
Node.js (V8)
'''
```



