# 代理IP

现在我们对爬虫有一定程度的了解了，但针对于反爬技术我们还知之甚少。虽然我们尽力的将爬虫伪装成用户使用浏览器浏览页面的行为，**但一般爬虫请求服务器中网页资源的频率也大大高于普通用户请求的频率**，若网站服务器设置了反爬，当网站服务器检测到这些访问来自同一IP时，服务器会在**一段时间内拒绝来自该IP的请求服务**，并返回一些错误信息（`403状态码 Forbidden`）。这种情况就称为 **封IP**，于是乎网站就成功把我们的爬虫禁掉了。

![timg](image/timg.jpg)

针对这种反爬措施，**最直接的就是： 延迟 `time.sleep(时间)`，降低网站的访问频率。**但如果我们需要快速的爬取数据，又担心爬虫被封禁，那该怎么办呢？

试想一下，**既然服务器通过IP来封禁爬虫，那我们就多准备几个IP来伪装爬虫，让服务器认为是由多台机器发起的请求**，这样不就可以成功防止封 IP 了吗，这时**代理IP的作用**就显现了出来。

### 代理

##### 代理说明

打个比方，商场搞活动，一张券换一桶油，但是一个人只能换一次。A有两张券，A去换了一桶油，假如A第二次去换油必然遭到拒绝，这时A找到了B，把券给了B，让B去换油回来给A，这样A就换到了两桶油，B就可以说是A的代理。简单说，**代理就是代替他人完成某项任务**。

##### 代理IP说明

**代理IP即代理服务器（Proxy Server）是一种重要的安全功能**。

**代理IP组成**：`IP地址:端口号`，例如`121.237.149.249:3000`

IP是上网需要唯一的身份地址，身份凭证，而**代理IP就是我们上网过程中的一个中间平台，是由你的电脑先访问代理IP，之后再由代理IP访问你点开的页面，所以在这个页面的访问记录里留下的是就是代理IP的地址，而不是你的电脑本机IP**。

主要的功能之一：**提高下载速度，突破限制。**例如有些网站提供的下载资源，做了一个IP一个线程的限制，这时候就可以使用代理IP突破下载限制。

![QQ截图20200411212749](image/QQ截图20200411212749.png)

##### 代理IP分类

根据匿名分为两类：普通匿名代理、高度匿名代理。

**普通匿名代理**：代理服务器通常会加http头 `HTTP_VIA HTTP_X_FORWARD_FOR`，可能能查到客户端的IP。

**高度匿名代理**：会将数据包原封不动转发，服务端记录的是代理服务器的ip。

根据费用分为两类：免费代理、付费代理。

**免费代理**：免费，可用IP数量少，IP可用率低(大家都在用)，IP访问慢、不稳定。

**付费代理**：付费，可用IP数量多(和付费价格有关)，IP可用率高。(**强烈建议在商用项目中使用付费代理**)

![QQ截图20200406200710](image/QQ截图20200406200710.png)

##### 获取代理IP

**网站获取**：获取免费代理IP，比如[西刺免费代理IP](http://www.xicidaili.com/) ，但是这些免费代理大多数情况下都是不好用的，**所以比较靠谱的方法是购买付费代理，付费代理在很多网站都有售卖，数量不用太多，稳定、可用即可。**

**软件获取**：相关代理软件的话，比如[芝麻代理](http://www.zhimaruanjian.com/)，一般会在本机创建 HTTP或SOCKS 代理服务。若软件在本地 9743 端口上创建 HTTP 代理服务，即代理为 `127.0.0.1:9743`，只要设置了这个代理，就可以成功将本机IP切换到代理软件连接的服务器的IP了。

##### 设置代理

在 `requests` 中代理的设置很简单，只需要构造代理字典，然后通过 `proxies` 参数即可，**其运行结果的叫 `origin` 也是代理的 IP，这证明代理已经设置成功**。

```python
import requests

# 软件在本地9743端口上创建HTTP代理服务，即代理为127.0.0.1:9743
proxy = '127.0.0.1:9743'
# 构造字典，'http'、'https'
proxies = {
    'http': 'http://' + proxy,
    'https': 'https://' + proxy,
}
response = requests.get('http://httpbin.org/get', proxies=proxies)
print(response.text)


'''
结果：
{
  "args": {}, 
  "headers": {
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8", 
    "Accept-Encoding": "gzip, deflate", 
    "Accept-Language": "zh-CN,zh;q=0.9", 
    "Connection": "close", 
    "Host": "httpbin.org", 
    "Upgrade-Insecure-Requests": "1", 
    "User-Agent": "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36"
  }, 
  # 这里的IP就是代理IP，非本机IP。
  "origin": "117.139.208.10", 
  "url": "http://httpbin.org/get"
}
'''
```

### 代理池

##### 代理池简介

利用代理可以解决目标网站封 IP 的问题。但代理不论是免费的还是付费的，都不能保证都是可用的，因为可能 IP 被其他人使用来爬取同样的目标站点而被封禁，或者代理服务器突然发生故障或网络繁忙旦我们选用了一个不可用的代理，这势必会影响爬虫的工作效率。

所以，需要提前筛选，将不可用的代理剔除掉，保留可用代理，搭建一个高效易用的代理池。**简单说，代理池就是有效代理的集合。**

##### 模块处理流程

获取模块： **需要定时在各大代理网站抓取代理**。

检测模块： **需要定时检测数据库中的代理**。

存储模块： **负责存储抓取下来的代理**。

接口模块： **需要用 API 来提供对外服务的接口**。

**处理流程**：将代理池运行起来，在各大代理网站抓取代理，可用代理设置为100，不可用代理分数减1。本机的代理池配置运行在5555端口，浏览器访问http://127.0.0.1:5555/random ，即可获取随机一个可用代理。我们只需要访问此接口即可获取一个随机可用代理。

详情参考：[IP代理池](https://blog.csdn.net/HYdongdong2063/article/details/91867296)

```python
import requests

# 获取代理IP的接口
PROXY_POOL_URL = 'http://127.0.0.1:5555/random'
# 访问'http://127.0.0.1:5555/random'接口从代理池获取随机可用代理
def get_proxy():
    try:
        response = requests.get(PROXY_POOL_URL)
        if response.status_code == 200:
        	# 返回随机代理IP
            return response.text
    except ConnectionError:
        return None

# 使用get_proxy()方法获取一个随机代理
proxy = get_proxy()
proxies = {
    'http': 'http://' + proxy,
    'https': 'https://' + proxy,
}
# 使用代理IP打开http://httpbin.org/get测试连接，输出结果
try:
    response = requests.get('http://httpbin.org/get', proxies=proxies)
    print(response.text)
except requests.exceptions.ConnectionError as e:
    print('Error', e.args)

# 多次访问代理池接口
print(get_proxy())
print(get_proxy())
print(get_proxy())

'''
结果：
{
  "args": {}, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Connection": "close", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.19.1"
  }, 
  "origin": "46.173.191.51", 
  "url": "http://httpbin.org/get"
}
# 当中origin字段就是代理ip，每次访问代理池接口都会返回不同的代理IP。
185.136.158.7:1080
189.195.162.222:53281
195.238.85.215:50948
'''
```

