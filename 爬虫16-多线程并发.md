# 多线程并发

我们目前写的爬虫，看似爬取效率还可以，但实则效率并不高，这是因为我们所写的**爬虫本身是单线程的，这就导致爬取页面的机制是串行的，也就是说，必须等到第一个页面的访问、下载、采集、入库等一系列操作都完成以后，爬虫才会去爬取第二个页面，而在访问、下载过程中CPU资源是闲置的，而在采集、入库操作中网络资源是闲置的，假如某个操作时间过长必然会延长采集时间，降低爬虫效率。**这个时候，使用多线程的优势就显现了出来。

### 多线程编程

关于基础概念请回看《[基础15-进程、线程、协程、效率](基础15-进程、线程、协程、效率.md)》

##### 基础回顾

**进程**：**计算机运行程序时产生的过程，同时也是CPU资源分配的最小单位。**

**线程**：**线程是对进程更小维度的划分，同时也是CPU调度的最小单位。**

**并发**：简单说，就是**在一个时间段执行多个请求，任意时间点执行一个请求**的执行方式。

**并行**：简单说，就是**在一个时间段执行多个请求，任意时间点执行多个请求**的执行方式。

**I/O密集型任务**：**指磁盘I/O、网络I/O占主要的任务，输入输出量很大，计算量很小**（请求网页、 读写文件等）。

I/O密集型特点：**需要等待时间**，最适合方法就是，遇到延时操作时，就去执行其他的线程，即**多线程**。

**CPU密集型任务**：**计算密集型任务**，**指CPU计算占主要的任务，输入输出量很小，计算量很大**（复杂运算等）。

CPU密集型特点：**需要CPU的算力**，最适合方法就是，充分利用多核CPU，即**多进程**。

##### 多线程优势

**根据爬虫的特点，按照任务类型分类，爬虫属于“I/O密集型任务”。**针对“I/O密集型任务”解决方法就是：多线程。比较相较于其他方法的优势在于：

1. **单线程下有IO操作会进行IO等待，造成不必要的时间浪费。**
2. **多线程能在线程A等待时，自动切换到线程B，减少浪费CPU的资源，从而能提升程序执行效率。**
3. **多进程利用 CPU 的多核优势，能同执行多个任务，但系统实现需要准备工作、耗费时间、资源开销大。**

##### 单线程程序

单线程在程序运行上是**串行同步**的，**只有上一步程序运行完成后，才会运行下一步程序，否则一直等待**。

```python
import time

def hello():
    print('Hello world!')
    time.sleep(1)
    print('Hello again!')

for num in range(2):
    hello()

'''
输出：
Hello world!
（暂停1秒）
Hello again!
Hello world!
（暂停1秒）
Hello again!

解释：因为没有使用多线程或多进程，程序中只有一个执行单元，而time.sleep(1)的休眠操作会让整个线程停滞1秒钟，在这段时间里面CPU是完全闲置的没有做什么事情。
'''
```

##### 多线程程序

将上面的程序，按照多线程的写法看看会有上面结果：

```python
import time
import threading

def run():
    print('Hello world! (%s)' % threading.currentThread())
    time.sleep(1)
    print('Hello again! (%s)' % threading.currentThread())

t1 = threading.Thread(target=run)
t2 = threading.Thread(target=run)
# 启动子线程t1、t2
t1.start()
t2.start()
# 阻塞主线程，等待子线程t1、t2执行结束
t1.join()
t2.join()
'''
输出：
Hello world! (<Thread(Thread-1, started 83108)>)
Hello world! (<Thread(Thread-2, started 86836)>)
(暂停约1秒)
Hello again! (<Thread(Thread-2, started 86836)>)
Hello again! (<Thread(Thread-1, started 83108)>)

解释1：多线程程序中，根据线程ID可以看到该段程序运行过程中，生成了两个新的子线程，两个子线程分别完整的运行了一次run函数。
解释2：两次运行run函数，共同等待了一秒，这说明CPU在一个线程执行遇到了延时操作time.sleep(1)，就切换到另一个线程上执行函数，减少了CPU闲置时间，提高了利用效率。
解释3：因为GIL锁存在，两个线程看似同时在运行，实则是在交替运行，在任意一个时间点只有一个线程处于执行状态，也就是本该并行的多线程，被GIL强行转成并发的单线程。因此许多人讲，Python的多线程实际上就是“伪多线程”。
'''
```

### 爬虫效率对比

为了更直观的看到多线程对爬虫效率的提升，下面比较单线程爬虫和多线程爬虫爬取相同内容的效率：

##### 单线程爬虫

```python
'''
网址：爬取豆瓣豆瓣电影 Top 250
目的：测试单线程爬虫爬取250个URL效率
'''
import re
import time
import requests
from fake_useragent import UserAgent

# 电影详情网页
def parse(url):
    m_response = requests.get(url, headers=headers)
    m_webcode = re.sub(r'\s*', '', m_response.text)
    # 获取电影名字、评分、导演、语言
    try:
        m_name = re.search(r'name="title"value="(.*?)"', m_webcode).group(1)
        m_score = re.search(r'property="v:average">(.*?)<',m_webcode).group(1)
        m_director = re.search(r'rel="v:directedBy">(.*?)<', m_webcode).group(1)
        m_language = re.search(r'语言:</span>(.*?)<br/>', m_webcode).group(1)
        print(m_name, m_score, m_director, m_language)
    except:
        print('页面不存在')

if __name__ == '__main__':
    start_time = time.time()
    m_urls = []
    # 获取全部电影网页url
    urls = ['https://movie.douban.com/top250?start=%d&filter='%(i*25) for i in range(0,10)]
    for url in urls:
        headers = {'User-Agent': UserAgent(use_cache_server=False).chrome}
        response = requests.get(url, headers=headers)
        webcode = re.sub(r'\s*', '', response.text)
        for item in re.findall(r'<divclass="item">.*?</div>', webcode):
            m_href = re.search(r'href="(.*?)"', item).group(1)
            m_urls.append(m_href)
    # 爬取250部电影
    for m_url in m_urls:
        parse(m_url)
    end_time = time.time()
    print(f'花费时间：{end_time-start_time}') 
'''
输出：
肖申克的救赎TheShawshankRedemption‎(1994) 9.7 弗兰克·德拉邦特 英语
...
黑客帝国2：重装上阵TheMatrixReloaded‎(2003) 8.6 莉莉·沃卓斯基 英语/法语
花费时间：224.8161380290985（爬取三次取平均值）
'''
```

##### 多线程爬虫

```python
'''
网址：爬取豆瓣豆瓣电影 Top 250
目的：测试多线程爬取250个URL的效率
'''
import re
import time
import threading
import requests
from fake_useragent import UserAgent

# 创建一个线程锁对象lock
lock = threading.Lock()

# 电影详情网页
def parse(url):
    headers = {'User-Agent': UserAgent(use_cache_server=False).chrome}
    response = requests.get(url, headers=headers)
    m_webcode = re.sub(r'\s*', '', response.text)
    # 加锁是为了防止多线程输出混乱
    with lock:
        # 获取电影名字、评分、导演、语言
        try:
            m_name = re.search(r'name="title"value="(.*?)"', m_webcode).group(1)
            m_score = re.search(r'property="v:average">(.*?)<',m_webcode).group(1)
            m_director = re.search(r'rel="v:directedBy">(.*?)<', m_webcode).group(1)
            m_language = re.search(r'语言:</span>(.*?)<br/>', m_webcode).group(1)
            print(m_name, m_score, m_director, m_language)
        except:
            print('页面不存在')

if __name__ == '__main__':
    start_time = time.time()
    m_urls = []
    # 获取全部电影网页url
    urls = ['https://movie.douban.com/top250?start=%d&filter='%(i*25) for i in range(0,10)]
    for url in urls:
        headers = {'User-Agent': UserAgent(use_cache_server=False).chrome}
        response = requests.get(url, headers=headers)
        webcode = re.sub(r'\s*', '', response.text)
        for item in re.findall(r'<divclass="item">.*?</div>', webcode):
            m_href = re.search(r'href="(.*?)"', item).group(1)
            m_urls.append(m_href)
    # 定义一个列表，向里面追加线程
    threads = []
    for m_url in m_urls:
        # 注意args()里面的内容必须是元组，只有一个元素时，必须要加上逗号
        t = threading.Thread(target=parse, args=(m_url,))
        threads.append(t)
    for t in threads:
        t.start()  # 调用start()方法，开始执行
    for t in threads:
        t.join()  # 子线程调用join()方法，使主线程等待子线程运行完毕之后才退出
    end_time = time.time()
    print(f'花费时间：{end_time-start_time}')
'''
输出：
页面不存在（'电影"V字仇杀队"网页失效'）
...
聚焦Spotlight‎(2015) 8.8 汤姆·麦卡锡 英语
花费时间：11.488420009613037（爬取三次取平均值）
'''
```

##### 效率对比总结

通过上面单线程爬虫和多线程爬虫的爬取用时和输出结果，可得出如下结论：

1. **多线程爬虫效率更高，因为多线程能解决很多IO阻塞问题，而且爬取的数量越大，效率提升的就越明显。**
2. **单线程爬虫的结果输出顺序和网页的排版顺序一致，多线程爬虫的结果输出顺序则是谁先处理完就输出谁。**
3. **单线程爬虫不用考虑资源竞争的问题，多线程爬虫需要考虑资源竞争、数据混乱和死锁的问题。**

