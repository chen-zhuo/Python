# 程序运行概念、并发编程

现如今，我们使用的计算机早已是多 CPU 或多核的计算机，而我们使用的操作系统基本都支持“多任务”，这使得我们可以同时运行多个程序，也可以将一个程序分解为若干个相对独立的子任务，让多个子任务“并行”或“并发”的执行，从而缩短程序的执行时间，同时也让用户获得更好的体验。

## 程序运行概念

### 核与任务

首先，我们需要了解核与任务的关系。购买电脑时经常会听到8核、16核处理器，这里的核指的就是**CPU的核芯数**。“核芯数与任务数”的关系，就相当于“人数和事情数”的关系，打个形象的比喻：

```
单核单任务：一个人，喝完酒，然后抽完烟，最后吃完烤鸭。
解释：单核就是一个人，喝酒就是一个任务，喝完酒后，又执行抽烟这个任务，抽完烟后，又执行吃烤鸭这个任务，最后吃完烤鸭，任务结束。
原理：一个核，在执行完一个任务后，才会去执行下一个任务。

单核多任务：一个人，喝一口酒，抽一口烟，吃一口烤鸭，轮换进行。
解释：单核就是一个人，喝酒就是一个任务，喝酒还没结束，又去执行抽烟这个任务，抽烟还没结束，又去执行吃烤鸭这个任务。
原理：一个核，在执行一个任务过程当中，会切换去执行另一个任务。

多核多任务：三个人，一个人喝酒，一个人抽烟，一个人吃烤鸭。
解释：多核就是多个人，每个人各执行一个喝酒、抽烟、吃烤鸭的任务，互不干扰。
原理：多个核，可以同时执行多个任务（当任务数等于核芯数时，效率最高）。
```

### 同步异步

根据上面**任务执行的过程**我们可以分为两个概念：**同步**（synchronous ）、**异步**（asynchronous）

```
单核单任务原理：一个核，在执行完一个任务后，才会去执行下一个任务。
解释：执行第二个任务的动作，是建立在执行完第一个任务的结果上，这就是一个同步的过程。
同步：只有当任务1完成后，才会执行任务2，否则会一直等待任务1完成的结果。

单核多任务原理：一个核，在执行一个任务过程当中，会切换去执行另一个任务。
解释：执行第二个任务的动作，和第一个任务是否执行完成没有任何关系，这就是一个异步的过程。
异步：执行任务2的时候，不会等待任务1完成的结果。
```

**总结：同步会对操作结果进行等待；异步不会对操作结果进行等待。**

### 阻塞性

根据上面**任务执行的状态**我们可以分为两个概念：**阻塞**（blocking）、**非阻塞**（nonblocking）

```
单核单任务原理：一个核，在执行完一个任务后，才会去执行下一个任务。
解释：执行第一个任务过程当中出现了间隙，但又不能利用间隙执行第二个任务，这就是阻塞。
阻塞：执行任务1的过程当中，不能执行其他任务。

单核多任务原理：一个核，在执行一个任务过程当中，会切换去执行另一个任务。
解释：执行第一个任务过程当中出现了间隙，然而利用了间隙去执行第二个任务，这就是非阻塞。
非阻塞：执行任务1的过程当中，可以执行其他任务。
```

同步异步与阻塞性：

1. **同步阻塞**：你打电话给114查路线，客服在查询过程中，你一直在接听电话。
2. **同步非阻塞**：你打电话给114查路线，客服在查询过程中，你一直在接听电话并且还打了一局游戏。
3. **异步阻塞**：你打电话给114查路线，客服说查好之后打给你，但这期间你什么都没做，一直在等回复。
4. **异步非阻塞**：你打电话给114查路线，客服说查好之后打给你，这期间你打了一局游戏。

### 并发并行

根据上面**任务执行的方式**两个重要的概念：**并发**（concurrency）、**并行**（parallel）。

```
单核多任务原理：一个核，在执行一个任务过程当中，会切换去执行另一个任务。
解释：一个核，在一个时刻只能执行一个任务，在一段时间内在不同的任务上来回切换执行，这就是并发。
```

**并发，指同一时刻只能有一条指令执行，但是多个指令流被快速轮换地执行。比如一个处理器，它先执行A指令流的指令一段时间，再执行B指令流的指令一段时间，再切回到指令流A执行一段时间。由于处理器执行指令的速度和切换的速度极快，人们完全感知不到计算机在这个过程中有多个指令流切换上下文执行的操作，这就使得宏观上看起来多个指令流在同时运行，但微观上其实只有一个指令流在执行。简单说，宏观上（一个时段）是多个程序运行，微观上（一个时刻）是单个程序顺序执行。**

```
多核多任务原理：多个核，可以同时执行多个任务（当任务数等于核芯数时，效率最高）。
解释：多个核，在一个时刻能同时执行多个任务，在一段时间内也能同时执行多个任务，这就是并行。
```

**并行，指同一时刻有多条指令在多个处理器上同时执行，并行必须要依赖于多核处理器，不论是从宏观上还是微观上，多个指令流可以在同一时刻一起执行的。简单说，就是“并排行走”或“同时实行或实施”，宏观和微观都是多个程序运行。**

## 并发编程

很多时候，我们并不用严格区分并发和并行两个词，所以我们有时候也把 Python 中的多线程、多进程以及异步 I/O 都视为实现并发编程的手段，但实际上前面两者也可以实现并行编程。

### 进程(`Process`)

上面提到了一个“指令流”的说法，因此我们需要先了解两个重要的概念：进程和线程。

**程序：计算机中静态的可执行文件。**

**进程：计算机运行程序时产生的动态的、有周期的（程序开始运行到运行结束）过程。**

1. **一个程序可以有多个进程，但至少要有一个进程。**
2. **程序占用的是磁盘空间；进程占用的是CPU、内存。**
3. **磁盘、硬盘属于外存储器，不属于计算机的运行资源；CPU、内存属于计算机的运行资源。**
4. **不同时间运行相同程序，产生的进程是不同的，因为进程占用的内存段、内存大小、运行时间都发生了变化。**

进程属性：

特点：**进程是CPU资源分配的最小单位，每个进程都有自己的地址空间、数据栈以及其他的数据**。

优点：**进程有独立的地址空间，当一个进程崩溃后，不会影响其他的进程。**

缺点：**在进程之间切换系统资源开销大，数据通信不方便，效率差。**

#### 多进程

**每个程序都至少有的一个进程，就是主进程，且每个进程都有自己的地址空间，即进程id(PID)。**

```python
import os

# os.getpid输出当前进程的id
print('我是主进程，PID是%s' % os.getpid())  # 输出：我是主进程，PID是10432
'''
# 注释：前面提到不同时间运行相同程序，产生的进程是不同的，因此这个PID值是动态的。
'''
```

**Python内置的 `multiprocessing` 进程模块，提供了 `Process` 类来创建子进程对象，通过该模块创建的进程，都是主进程下面的子进程。**

```python
import os
# multiprocessing导入Process类
from multiprocessing import Process

def coding():
    print('开始写代码，PID是%s' % os.getpid())
    print('休息一会儿，PID是%s' % os.getpid())


if __name__ == '__main__':
    # 通过Process类创建子进程对象p1，target参数接收函数coding作为子进程对象的内容
    p1 = Process(target=coding)
    # 启动子进程p1
    p1.start()
'''
输出：
开始写代码，PID是4328
休息一会儿，PID是4328
# 注释：4328就是子进程的id值。
'''
```

!> 注意：调用 `multiprocessing` 模块的函数要在 `if __name__ == '__main__':` 下执行，不然子进程会自动import启动它的这个文件，无限递归创建子进程，进而报错。

上面的程序运行中会有两个进程，一个是主进程，一个是创建的子进程，在任务管理器详细信息也能看到：

![QQ截图20191228215503](image/QQ截图20191228215503.png)

**进程传参**：进程传递参数使用args，但注意必须是元组类型。

```python
import multiprocessing

def run(a, b, c):
    print('启动子进程')
    print(f'传递的参数为{a,b,c}')
    print('结束子进程')

if __name__ == '__main__':
    # 加上要传递的参数args(元组类型)
    t1 = multiprocessing.Process(target=run, args=(1, '2', {'c':3},))
    # 启动子进程t1
    t1.start()
'''
输出：
启动子进程
传递的参数为(1, '2', {'c': 3})
结束子进程
'''
```

**进程阻塞**：如果子进程存在大量的耗时的运算，**主进程往往先于子进程之前结束执行**，但如果需要使用到子进程的计算结果，**就必须让主进程等待子进程运行完毕，再执行主进程**，这就是**阻塞进程**。

```python
import os
import time
from multiprocessing import Process

def coding():
    print('开始写代码，PID是%s' % os.getpid())
    print('休息一会儿，PID是%s' % os.getpid())


if __name__ == '__main__':
    print('无阻塞输出：')
    print('我是主进程，PID是%s' % os.getpid())
    p1 = Process(target=coding)
    p1.start()
    print('我是主进程，PID是%s' % os.getpid())
    time.sleep(5)
    print('*' * 20)
    print('有阻塞输出：')
    print('我是主进程，PID是%s' % os.getpid())
    p2 = Process(target=coding)
    p2.start()
    # 阻塞主进程，等待子进程p2执行结束
    p2.join()
    print('我是主进程，PID是%s' % os.getpid())
'''
无阻塞输出：
我是主进程，PID是1156
我是主进程，PID是1156
开始写代码，PID是2864
休息一会儿，PID是2864
# 注释：可以看到主进程先于子进程输出，也就是说主进程比子进程更快的执行结束。
********************
有阻塞输出：
我是主进程，PID是1156
开始写代码，PID是10312
休息一会儿，PID是10312
我是主进程，PID是1156
# 注释：当子进程执行结束以后，才结束了主进程，说对主进程进行了阻塞等到子进程执行结束。
'''
```

?> 提示：在多进程程序中，如果某个进程p1一直阻塞，导致后面的进程p2、p3执行不了。可以直接去结束进程p1，进程p2和p3就会执行了，这也说明进程之间是互不影响的。

#### 进程通信

先给大家一个任务：启动两个进程，一个输出“Ping”，另一个输出“Pong”，当数量加起来等于50个时，就结束程序。听起来是不是非常简单，但实现却有一定难度，例如下面的代码实际执行的结果是“Ping”和“Pong”各输出了50个：

```python
import time
from multiprocessing import Process

counter = 0

def sub_task(string):
    global counter
    while counter < 50:
        print(string, end='', flush=True)
        counter += 1
        time.sleep(0.01)

def main():
    Process(target=sub_task, args=('Ping', )).start()
    Process(target=sub_task, args=('Pong', )).start()


if __name__ == '__main__':
    main()
```

**这是由于进程之间不能直接通过共享内存的方式交换数据，当我们在程序中创建进程的时候，子进程会复制父进程及其所有的数据结构，每个子进程有自己独立的内存空间，这也就意味着两个子进程中各有一个 `counter` 变量，它们都会从0加到50，所以结果就可想而知了。**要解决这个问题，可以使用 `multiprocessing` 模块中的 `Queue` 类，它是可以被多个进程共享的队列，底层是通过操作系统底层的管道和信号量（semaphore）机制来实现的，代码如下所示。

```python
import time
from multiprocessing import Process, Queue

def sub_task(content, queue):
    counter = queue.get()
    while counter < 50:
        print(content, end='', flush=True)
        counter += 1
        queue.put(counter)
        time.sleep(0.01)
        counter = queue.get()

def main():
    queue = Queue()
    queue.put(0)
    p1 = Process(target=sub_task, args=('Ping', queue))
    p1.start()
    p2 = Process(target=sub_task, args=('Pong', queue))
    p2.start()
    while p1.is_alive() and p2.is_alive():
        pass
    queue.put(50)


if __name__ == '__main__':
    main()
'''
注释：上面的代码通过Queue类的get和put方法让三个进程（p1、p2和主进程）实现了数据的共享，这就是所谓的进程间的通信，通过这种方式，当Queue中取出的值已经大于等于50时，p1和p2就会跳出while循环，从而终止进程的执行。代码第22行的循环是为了等待p1和p2两个进程中的一个结束，这时候主进程还需要向Queue中放置一个大于等于50的值，这样另一个尚未结束的进程也会因为读到这个大于等于50的值而终止。
'''
```

> **提示**：`multiprocessing.Queue`对象的`get`方法默认在队列为空时是会阻塞的，直到获取到数据才会返回。如果不希望该方法阻塞以及需要指定阻塞的超时时间，可以通过指定`block`和`timeout`参数进行设定。

#### 进程池

**事实上，进程的创建和释放都会带来很大的开销，频繁的创建和释放进程通常都不是很好的选择。利用进程池，可以提前准备好若干个进程，在使用的过程中不需要再通过自定义的代码创建和释放进程，而是直接复用进程池中的进程。**Python 内置的 `concurrent.futures` 模块提供了对进程池的支持，代码如下所示。

```python
import time
import random
from concurrent.futures import ProcessPoolExecutor

def download(filename):
    start = time.time()
    print(f'开始下载 {filename}.')
    time.sleep(random.randint(3, 6))
    print(f'{filename} 下载完成.')
    end = time.time()
    print(f'下载耗时: {end - start:.2f}秒.')

def main():
    with ProcessPoolExecutor(max_workers=4) as pool:
        filenames = ['Python从入门到住院.pdf', 'MySQL从删库到跑路.avi', 'Linux从精通到放弃.mp4']
        start = time.time()
        for filename in filenames:
            pool.submit(download, filename=filename)
    end = time.time()
    print(f'总耗时: {end - start:.2f}秒.')


if __name__ == '__main__':
    main()
```

### 线程(`Thread`)

**线程：线程是对进程更小维度的划分**

1. **一个进程可以有多个线程，但至少有一个线程。**
2. **多个线程共享一个进程的内存空间**，进程相当于教室，线程就相当于教室里面的学生，他们共用这一间教室。

线程属性：

特点：**线程是CPU调度的最小单位，且线程没有独立的地址空间。**

优点：**由于没有独立的地址空间，需要共享数据和内存，资源消耗少，并发性高，运行效率高。**

缺点：**没有独立的地址空间，一个线程死掉会影响其他的线程进而导致整个进程就死掉，因此多线程比多进程更脆弱；按时间片强制切换线程，不够灵活。**

#### 多线程

**所有的进程默认都有一个线程**，一般叫这个线程为**主线程**。

```python
import threading
print('线程数量:', threading.activeCount())
'''
输出：
线程数量: 1
'''
```

**Python内置的 `threading` 线程模块，提供了 `Thread` 类来创建子线程对象，通过 `threading` 模块创建的线程程，都是主线程下面的子线程。**

```python
import threading

def run():
    print('启动线程')
    print('线程数量:', threading.activeCount())
    print('结束线程')

if __name__ == '__main__':
    print('线程数量:', threading.activeCount())
    # 创建子线程对象t1，target参数接收函数run的地址
    t1 = threading.Thread(target=run)
    # 启动子线程t1
    t1.start()
'''
输出：
线程数量: 1
启动线程
线程数量: 2
结束线程
注释：程序运行中会有两个线程，一个是主线程，一个是创建的子线程。
'''
```

!> 注意：调用 threading 模块的函数可以不用在 `if __name__ == '__main__':` 下执行。

**线程传参**：与进程一样，传递参数使用args，但注意必须是元组类型。

```python
import threading

def run(a, b, c):
    print('启动子线程')
    print(f'传递的参数为{a,b,c}')
    print('结束子线程')

# 加上要传递的参数args(元组类型)
t1 = threading.Thread(target=run, args=(1, '2', {'c':3},))
# 启动子线程t1
t1.start()
# 等待子线程t1结束
t1.join()
'''
输出：
启动子线程
传递的参数为(1, '2', {'c': 3})
结束子线程
'''
```

**线程阻塞**：与进程一样，但如果需要使用到子线程的计算结果，**就必须让主线程等待子线程运行完毕，再执行主线程**，这就是**阻塞线程**。

```python
# 无阻塞
import threading

def run():
    print('子线程开始')
    print('子线程结束')

if __name__ == '__main__':
    print('无阻塞输出：')
    print('主线程开始')
    # 创建子线程对象t1，target参数接收函数run的地址
    t1 = threading.Thread(target=run)
    # 启动子线程t1
    t1.start()
    print('主线程结束')

    print('有阻塞输出：')
    print('主线程开始')
    # 创建子线程对象t1，target参数接收函数run的地址
    t2 = threading.Thread(target=run)
    # 启动子线程t1
    t2.start()
    # 阻塞主线程，等待子线程t1执行结束
    t2.join()
    print('主线程结束')
'''
无阻塞输出：
主线程开始
子线程开始
主线程结束
子线程结束
# 注释：这里和上面进程的例子一样，也是主线程先于子线程结束。

有阻塞输出：
主线程开始
子线程开始
子线程结束
主线程结束
# 注释：这里和上面进程的例子一样，通过阻塞，子线程都结束了，才让主线程结束。
'''
```

看一个例子，下面的三个下载任务之间并没有逻辑上的因果关系，三者是可以“并发”的，下一个下载任务没有必要等待上一个下载任务结束，为此，我们可以使用多线程编程：

```python
import time
import random
from threading import Thread

def download(filename):
    start = time.time()
    print(f'开始下载 {filename}.')
    time.sleep(random.randint(3, 6))
    print(f'{filename} 下载完成.')
    end = time.time()
    print(f'下载耗时: {end - start:.3f}秒.')

def main():
    threads = [
        Thread(target=download, kwargs={'filename': 'Python从入门到住院.pdf'}),
        Thread(target=download, kwargs={'filename': 'MySQL从删库到跑路.avi'}),
        Thread(target=download, kwargs={'filename': 'Linux从精通到放弃.mp4'})
    ]
    start = time.time()
    # 启动三个线程
    for thread in threads:
        thread.start()
    # 等待线程结束
    for thread in threads:
        thread.join()
    end = time.time()
    print(f'总耗时: {end - start:.3f}秒.')

if __name__ == '__main__':
    main()
'''
开始下载 Python从入门到住院.pdf.
开始下载 MySQL从删库到跑路.avi.
开始下载 Linux从精通到放弃.mp4.
MySQL从删库到跑路.avi 下载完成.
下载耗时: 3.005秒.
Python从入门到住院.pdf 下载完成.
下载耗时: 5.006秒.
Linux从精通到放弃.mp4 下载完成.
下载耗时: 6.003秒.
总耗时: 6.004秒.
# 解释：通过上面的运行结果可以发现，整个程序的执行时间几乎等于耗时最长的一个下载任务的执行时间，这也就意味着，三个下载任务是并发执行的，不存在一个等待另一个的情况，这样做很显然提高了程序的执行效率。

简单的说，如果程序中有非常耗时的执行单元，而这些耗时的执行单元之间又没有逻辑上的因果关系，即B单元的执行不依赖于A单元的执行结果，那么A和B两个单元就可以放到两个不同的线程中，让他们并发的执行。这样做的好处除了减少程序执行的等待时间，还可以带来更好的用户体验，因为一个单元的阻塞不会造成程序的“假死”，因为程序中还有其他的单元是可以运转的。
'''
```

#### 线程锁

当多个线程同时操作一个变量时，线程不一定是**串行**(一个线程完完全全执行完毕后才进行下一个线程），因此**有些线程操作还没有结束时，就切换到了另一个线程上，导致了现数据混乱**，为了决解数据不一致的情况，就需要给线程加锁。

1. **有锁的线程才能操作数据，没有锁的线程就不能操作数据。**
2. 当一个有锁的线程操作完数据以后，**就必须要释放锁**，给其他线程上锁操作数据。
3. **死锁**：线程获得锁后，不释放锁，其他线程无休止的等待锁的释放。
4. **线程安全**：即线程加锁，多线程访问时，不会出现数据不一致或者数据污染。

```python
import threading

num = 0
def run():
    global num
    for i in range(1000000):
        num += i
        num -= i

# 创建一个线程锁对象lock
lock = threading.Lock()

num1 = 0
def run1():
    global num1
    for i in range(1000000):
        # with 线程锁对象：可以对线程自动上锁、解锁
        with lock:
            num1 += i
            num1 -= i

# 创建子线程对象
t1 = threading.Thread(target=run)
t2 = threading.Thread(target=run)
t3 = threading.Thread(target=run1)
t4 = threading.Thread(target=run1)
# 启动子线程
t1.start()
t2.start()
t3.start()
t4.start()
# 阻塞主线程，等待子线程t1、t2结束
t1.join()
t2.join()
t3.join()
t4.join()
print(num)
print(num1)
'''
第一次输出num：-1515072
第二次输出num：-3135633
第一次输出num1：0
第二次输出num1：0
# 注释：num数据结果的不一致，是因为受多个线程t1、t2操控一个变量num的影响，当线程t1还没有完成对变量num的全部操作时，就切换到了线程t2，在线程t2中变量num存储的仍然是线程t1未操作前的数据。
'''
```

#### 守护线程

**所谓“守护线程”就是在主线程结束的时候，不值得再保留的执行线程。这里的不值得保留指的是守护线程会在其他非守护线程全部运行结束之后被销毁，它守护的是当前进程内所有的非守护线程。简单的说，守护线程会跟随主线程一起挂掉，而主线程的生命周期就是一个进程的生命周期。**如果不理解，我们可以看一段简单的代码。

```python
import time
from threading import Thread

def display(content):
    while True:
        print(content, end='', flush=True)
        time.sleep(0.1)

def main():
    Thread(target=display, args=('Ping', )).start()
    Thread(target=display, args=('Pong', )).start()


if __name__ == '__main__':
    main()
'''
注释：我们将print函数的参数flush设置为True，这是因为flush参数的值如果为False，而print又没有做换行处理，就会导致每次print输出的内容被放到操作系统的输出缓冲区，直到缓冲区被输出的内容塞满，才会清空缓冲区产生一次输出。上述现象是操作系统为了减少 I/O 中断，提升 CPU 利用率做出的设定，为了让代码产生直观交互，我们才将flush参数设置为True，强制每次输出都清空输出缓冲区。
'''
```

上面的代码运行起来之后是不会停止的，因为两个子线程中都有死循环，除非你手动中断代码的执行。但是，如果在创建线程对象时，将名为`daemon`的参数设置为`True`，这两个线程就会变成守护线程，那么在其他线程结束时，即便有死循环，两个守护线程也会挂掉，不会再继续执行下去，代码如下所示。

```python
import time
from threading import Thread

def display(content):
    while True:
        print(content, end='', flush=True)
        time.sleep(0.1)

def main():
    Thread(target=display, args=('Ping', ), daemon=True).start()
    Thread(target=display, args=('Pong', ), daemon=True).start()
    time.sleep(5)


if __name__ == '__main__':
    main()
'''
注释：我们在主线程中添加了一行time.sleep(5)让主线程休眠5秒，在这个过程中，输出Ping和Pong的守护线程会持续运转，直到主线程在5秒后结束，这两个守护线程也被销毁，不再继续运行。
'''
```

#### 其他线程方法

**凑线程**：指**凑集一定的线程数**后，**再执行线程**的方式。

```python
import time
import threading

# 创建一个子线程数为3的对象bar
bar = threading.Barrier(3)

def run():
	# 因为是子线程，线程数量要减一
    print('当前活动的子线程数量:', threading.activeCount()-1)
    # 对象bar等待子线程数达到3
    bar.wait()
    print('子线程数量达到3')

# 循环创建5个子线程并启动
for i in range(5):
    threading.Thread(target=run).start()
'''
输出：
当前活动的子线程数量: 1
当前活动的子线程数量: 2
当前活动的子线程数量: 3
# 注释：这里线程数量达到了3，上面代码就以每个线程输出了一次，共三次
子线程数量达到3
子线程数量达到3
子线程数量达到3
# 注释：剩下的两个线程数量达不到3，上面代码就一次不输出。
当前活动的子线程数量: 1
当前活动的子线程数量: 2
'''
```

**延迟线程**：让子线程延迟指定时间执行。

```python
import threading

def run():
    print('启动线程')
    print('结束线程')

# 创建一个可定时启动的线程对象t1（通过start运行时，要等待5秒）
t1 = threading.Timer(5,run)
# 启动子线程t1
t1.start()
# 阻塞主线程，等待线程t1
t1.join()
print('结束')
'''
输出：
（5秒后）
启动线程
结束线程
结束
'''
```

除此之外，还有其他方法自行探究：

```
threading.currentThread()：返回当前的线程变量
threading.enumerate()：返回一个包含正在运行的线程的list
threading.TIMEOUT_MAX：设置threading全局超时时间
```

#### 线程池

**事实上，线程的创建和释放都会带来较大的开销，频繁的创建和释放线程通常都不是很好的选择。利用线程池，可以提前准备好若干个线程，在使用的过程中不需要再通过自定义的代码创建和释放线程，而是直接复用线程池中的线程。**Python 内置的 `concurrent.futures` 模块提供了对线程池的支持，代码如下所示。

```python
import time
import random
from concurrent.futures import ThreadPoolExecutor

def download(*, filename):
    start = time.time()
    print(f'开始下载 {filename}.')
    time.sleep(random.randint(3, 6))
    print(f'{filename} 下载完成.')
    end = time.time()
    print(f'下载耗时: {end - start:.3f}秒.')

def main():
    with ThreadPoolExecutor(max_workers=4) as pool:
        filenames = ['Python从入门到住院.pdf', 'MySQL从删库到跑路.avi', 'Linux从精通到放弃.mp4']
        start = time.time()
        for filename in filenames:
            pool.submit(download, filename=filename)
    end = time.time()
    print(f'总耗时: {end - start:.3f}秒.')


if __name__ == '__main__':
    main()
```

### 协程(`Coroutines`)

**协程，又称微线程，是对线程更小维度的划分。**和线程相比协程可以有上万次并发。回到之前的问题，因为协程在线程内，所以协程没有锁。

1. **一个进程可以有多个线程，一个线程可以有多个协程。**
2. 维度划分：**进程>=线程>=协程**。
3. **进程、线程切换都由系统控制，协程切换由程序猿控制。**

协程属性：

优点：**更高的并发，内存开销更小，自由切换，避免了无意义的调度；因为只有一个线程，不需要锁机制。**

缺点：**程序员必须自己承担调度责任，同时也失去了标准线程使用多核CPU的能力。**

#### asyncio模块

**Python 3.4版本引入 `asyncio`  标准库，内置了对异步IO的支持，可以实现单线程并发IO操作。**

- `event_loop` 事件循环：程序开启一个无限循环，把一些函数注册到事件循环上，当满足事件发生的时候，调用相应的协程函数。
- `coroutine` 协程：协程对象，指一个使用async关键字定义的函数，它的调用不会立即执行函数，而是会返回一个协程对象。协程对象需要注册到事件循环，由事件循环调用。
- `task` 任务：一个协程对象就是一个原生可以挂起的函数，任务则是对协程进一步封装，其中包含了任务的各种状态。
- `future`：代表将来执行或没有执行的任务的结果，本质上和task上没有的区别。
- `async/await` 关键字：python3.5用于定义协程的关键字，async定义一个协程，await用于挂起阻塞的异步调用接口。

`asyncio`编程模型：**从 `asyncio` 模块中直接获取一个 `EventLoop`（事件循环）的引用，然后把需要执行的 `coroutine`（协程）扔到 `EventLoop` 中执行，就实现了异步IO。**

?> 提示：`await` 关键字和 `async` 关键字一样，使用前都必须导入 `asyncio` 包。

#### 协程程序

首先我们写一个单协程程序执行它：

```python
# 首先我们要引入asyncio包，这样才能使用async关键字
import asyncio

# async把hello函数标记为协程对象
async def hello():
    print('Hello world!')
    print('Hello again!')

# 通过get_event_loop()建立事件循环
loop = asyncio.get_event_loop()
# 把hello协程对象注册到事件循环中执行
loop.run_until_complete(hello())

'''
输出：
Hello world!
Hello again!

# 注释：hello协程对象不能直接被运行，必须要封装为task或者future才能被运行，而run_until_complete方法可以自动将协程封装为task任务。
'''
```

接下来我们写一个多协程程序执行它：

```python
import asyncio
import threading

async def hello():
    print('Hello world! (%s)' % threading.currentThread())
    print('Hello again! (%s)' % threading.currentThread())

loop = asyncio.get_event_loop()
# 使用tasks列表保存3个hello协程对象
tasks = [hello() for _ in range(3)]
# 通过asyncio.wait方法接受单个或者多个协程对象组成的列表，再将他们注册到事件循环中执行
loop.run_until_complete(asyncio.wait(tasks))

'''
输出：
Hello world! (<_MainThread(MainThread, started 6928)>)
Hello again! (<_MainThread(MainThread, started 6928)>)
Hello world! (<_MainThread(MainThread, started 6928)>)
Hello again! (<_MainThread(MainThread, started 6928)>)
Hello world! (<_MainThread(MainThread, started 6928)>)
Hello again! (<_MainThread(MainThread, started 6928)>)

# 注释：由打印的当前线程名称可以看出，三个协程对象都是由同一个线程执行的。
'''
```

现在我们在多协程程序加上1秒延迟来执行它：

```python
import time
import asyncio
import threading

async def hello():
    print('Hello world! (%s)' % threading.currentThread())
    # 增加1秒延迟
    time.sleep(1)
    print('Hello again! (%s)' % threading.currentThread())

loop = asyncio.get_event_loop()
tasks = [hello() for _ in range(3)]
loop.run_until_complete(asyncio.wait(tasks))

'''
输出：
Hello world! (<_MainThread(MainThread, started 11160)>)
(1秒延迟)
Hello again! (<_MainThread(MainThread, started 11160)>)
Hello world! (<_MainThread(MainThread, started 11160)>)
(1秒延迟)
Hello again! (<_MainThread(MainThread, started 11160)>)
Hello world! (<_MainThread(MainThread, started 11160)>)
(1秒延迟)
Hello again! (<_MainThread(MainThread, started 11160)>)

# 注释：可以发现，我们增加了延迟，但程序并没有并发的去执行，而还是在串行执行。其原因就是time.sleep(1)是一个阻塞操作，在阻塞中没有交出执行权。
'''
```

为了让 `time.sleep(1)` 交出执行权，前面必须要加上一个 `await` 关键字，于是就变成了这样：

```python
await time.sleep(1)
```

但在运行过程中报错提示类型错误，其原因就是 `await` 后面的对象必须是如下格式之一：

- 一个原生的协程对象；
- 一个由 `types.coroutine` 修饰的生成器，这个生成器可以返回协程对象；
- 由一个包含 `__await__` 方法的对象返回的一个迭代器。

那我们可以将代码修改为这样：

```python
# 将time.sleep(1)封装为一个协程对象
async def sleep():
    time.sleep(1)

# 再通过await去调用协程对象
await sleep()
```

然而运行后，程序和上面一样还是再串行执行，其原因就是 `time.sleep(1)` 并不支持异步，那么我们就用asyncio模块自带的sleep方法，于是代码变成了这样：

```python
import asyncio
import threading

async def hello():
    print('Hello world! (%s)' % threading.currentThread())
    # asyncio.sleep(1)支持异步，await再让它交出执行权
    await asyncio.sleep(1)
    print('Hello again! (%s)' % threading.currentThread())

loop = asyncio.get_event_loop()
tasks = [hello() for _ in range(3)]
loop.run_until_complete(asyncio.wait(tasks))

'''
Hello world! (<_MainThread(MainThread, started 8420)>)
Hello world! (<_MainThread(MainThread, started 8420)>)
Hello world! (<_MainThread(MainThread, started 8420)>)
(1秒延迟)
Hello again! (<_MainThread(MainThread, started 8420)>)
Hello again! (<_MainThread(MainThread, started 8420)>)
Hello again! (<_MainThread(MainThread, started 8420)>)

# 注释：这一次我们实现了真正的并发执行。当执行到await命令，把asyncio.sleep(1)看成是一个耗时1秒的IO操作，但协程对象不会等待，而是暂停当前async函数的执行，把执行权交出去执行EventLoop中其他可以执行的coroutine，等到异步任务结束，再把执行权交回async函数，继续往下执行。这也就说明协程对象一旦阻塞会将CPU让出而不是让CPU处于闲置状态，这样就大大的提升了CPU的利用率。
'''
```

#### 高并发限制

asyncio可以支持非常高的并发量，假如并发量高的已经让电脑卡顿了，我们就需要对并发量进行限制。代码如下：

```python
import asyncio
import threading

# 借助Semaphore创建一个信号量对象，限制并发量为2个
semaphore = asyncio.Semaphore(2)

async def hello():
    # 有了信号量的控制，最大协程数量被限制在2个
    async with semaphore:
        print('Hello world! (%s)' % threading.currentThread())
        await asyncio.sleep(1)
        print('Hello again! (%s)' % threading.currentThread())

loop = asyncio.get_event_loop()
tasks = [hello() for _ in range(3)]
loop.run_until_complete(asyncio.wait(tasks))

'''
输出：
Hello world! (<_MainThread(MainThread, started 16324)>)
Hello world! (<_MainThread(MainThread, started 16324)>)
(1秒延迟)
Hello again! (<_MainThread(MainThread, started 16324)>)
Hello again! (<_MainThread(MainThread, started 16324)>)
Hello world! (<_MainThread(MainThread, started 16324)>)
(1秒延迟)
Hello again! (<_MainThread(MainThread, started 16324)>)

# 注释：这里可以看到，最大并发量被限制在2个，因此完全执行3个并发任务，一共延迟了2秒。
'''
```
