# 验证码

在爬取数据的过程中，难免会遇到各种各样的验证码来阻挡爬虫，绝大部分的验证码对于人来说还是很好识别并验证成功的。但爬虫不是人，只是一段死板的程序，没有人灵活思维和高效的识别，所以如何破解验证码是爬虫的一个难点，因为它涉及到的不仅仅是爬取数据还有图片识别、轨迹计算等其他方面的分析。

### 图形验证码

##### 安装识别软件

识别图片不仅仅需要识别库，还需要安装识别软件[tesseract-ocr](https://digi.bib.uni-mannheim.de/tesseract/)才能成功识别。

![20190910192903504](image/20190910192903504.png)

其中，文件名中带有dev的为开发版本，不带dev的为稳定版本，选择合适的版本进行安装。

安装过程中，其中可以勾选`Additional language data(download)`选项来安装OCR识别支持的语言包，识别多国语言。

![20190910193132115](image/20190910193132115.png)

将软件的安装路径添加到“系统变量”中Path中保存。

![QQ截图20200412162828](image/QQ截图20200412162828.png)

![QQ截图20200412162849](image/QQ截图20200412162849.png)

在后面使用过程中**可能会报这样的错误**：`RuntimeError: Failed to init API, possibly an invalid tessdata path:路径 `

**解决办法**：我们只需要将Tesseract_OCR安装路径下的tessdata的目录，拷贝到上面报错的`路径`中即可。

![20190910194054116](image/20190910194054116.png)

##### 安装识别库

当前大多数验证码还是图形验证码，针对这类验证码我们就可以使用 Python 的 OCR 识别库来识别。

**OCR (光学字符识别)**：指通过扫描字符，然后通过其形状将其翻译成电子文本的过程。

**pytesseract** ：是Google的Tesseract-OCR引擎包装器，但其实是对tesseract封装的一个Python库，可以用来识别图片中的字符。**所以，在使用pytesseract之前，我们需要安装tesseract。**

```python
# 先安装tesseract
pip install tesseract
# 后安装pytesseract
pip install pytesseract
```

!> pytesseract安装成功后，使用可能会报如下错误：`pytesseract.pytesseract.TesseractError: (1, ‘Error opening data file \Program Files (x86)\...`

![20190507152647652](image/20190507152647652.png)

解决方法：**设置环境变量 TESSDATA_PREFIX，它的值为Tesseract-OCR目录（安装识别软件会生成的目录）当中的tessdata目录。**设置完再次运行如果还报相同的错误，重启pycharm再运行，如果仍然报相同的错误，重启一下电脑在运行。

![20190910194054116](image/20190910194054116.png)

**tesserocr**：**即 OCR 识别库** ，但其实是对 tesseract 做的一层 Python API 封装，所以它的核心是 tesseract。 **因此，在安装 tesserocr 之前，我们需要先安装 tesseract 。**

```python
# 先安装tesseract
pip install tesseract
# 后安装tesserocr
pip install tesserocr
```

!> 绝大多数情况下，tesserocr库都不能安装成功，就需要手动下载进行安装，下载地址：https://github.com/simonflueckiger/tesserocr-windows_build/releases

![QQ截图20200416221030](image/QQ截图20200416221030.png)

根据自己的系统和安装的Python环境版本选择合适的库进行安装：

```
tesserocr-2.4.0-cp36-cp36m-win32.whl
2.4.0：tesserocr的版本
cp36：适合Python3.6的环境
win32：适合windows32位操作系统

tesserocr-2.4.0-cp37-cp37m-win_amd64.whl
2.4.0：tesserocr的版本
cp37：适合Python3.7的环境
win_amd64：适合windows64位操作系统
```

将库下载到本地，打开命令行进入到下载的tesserocr库位置，输入下面命令即可安装成功：

```
pip install tesserocr-2.4.0-cp37-cp37m-win_amd64.whl
```

##### 无背景图片验证码

无背景验证码：指的是**内容背景是单色的，无其花纹的验证码**。

![QQ截图20200411221942](image/QQ截图20200411221942.png)

这类验证码相对简单，tesserocr的**识别率还比较高**的。

```python
# 导入tesserocr
import tesserocr
# 导入图像模块
from PIL import Image

# 方法一：以图片对象的形式来识别的验证码
# 读取image.jpg图片
image = Image.open('image.jpg')
# 识别图片
code1 = tesserocr.image_to_text(image)
# 输出识别结果
print(f'code1识别结果：{code1}')	

# 方法二：以图片文件的形式来识别的验证码（此方法中图片的名称不能有中文否则会报错）
code2 = tesserocr.file_to_text('image.jpg')
# 输出识别结果
print(f'code2识别结果：{code2}')

'''
输出：
code1识别结果：8713
code2识别结果：8713
'''
```

同样的，使用pytesseract也能识别该验证码：

```python
# 导入pytesseract
import pytesseract
# 导入图像模块
from PIL import Image

# 读取image.jpg图片
image = Image.open('image.jpg')
# 识别图片
code1 = pytesseract.image_to_string(image)
# 输出识别结果
print(f'code1识别结果：{code1}')

'''
输出：
code1识别结果：8713
'''
```

##### 有背景图片验证码

有背景验证码：指的是**背景颜色多样，有花纹的验证码**。

![QQ截图20200412153026](image/QQ截图20200412153026.png)

对于有嘈杂的背景的验证码，**直接识别的识别率会很低**，因此我们就要对图片进行一定的处理，来提高识别率。大体步骤有三点：

1. **灰度化：以黑色为基准色，用不同的饱和度的黑色来显示图像，灰度图像的每个像素点色值在0-255，0代表纯黑，255代表纯白**

![QQ截图20200412160358](image/QQ截图20200412160358.png)

2. **二值化：将小于阈值(129)的像素点统一设置为黑色(0)，反之统一设置为白色(255)，得到黑白图像。**

![QQ截图20200412160409](image/QQ截图20200412160409.png)

3. **去噪点：检测像素点周围邻近的8个像素点，如果有4个即以上的白色像素点，则认为当前像素点是噪点，设置为白色，反之，则不是噪点，设置为黑色。**

![QQ截图20200412160420](image/QQ截图20200412160420.png)

```python
import tesserocr
import pytesseract
from PIL import Image

# 打开图片对象
image = Image.open('image.jpg')
# 图片灰度化
image1 = image.convert("L")
# 显示图片
image1.show()

# 图片二值化，129是二值化的阈值
image2 = image1.point(lambda x: 255 if x > 129 else 0)
image2.show()

# 去噪函数
def denoising(image):
    pixdata = image.load()
    # 获取图片宽高
    w, h = image.size
    # 遍历像素点
    for j in range(1, h - 1):
        for i in range(1, w - 1):
            count = 0
            l = pixdata[i, j]
            if l == pixdata[i, j - 1]:
                count = count + 1
            if l == pixdata[i, j + 1]:
                count = count + 1
            if l == pixdata[i + 1, j - 1]:
                count = count + 1
            if l == pixdata[i + 1, j + 1]:
                count = count + 1
            if l == pixdata[i + 1, j]:
                count = count + 1
            if l == pixdata[i - 1, j + 1]:
                count = count + 1
            if l == pixdata[i - 1, j - 1]:
                count = count + 1
            if l == pixdata[i - 1, j]:
                count = count + 1
            if count < 4:
                pixdata[i, j] = 255
    return image
# 去噪点
image3 = denoising(image2)
image3.show()

# 识别处理后验证图片对象
res1 = tesserocr.image_to_text(image3)
print(f'tesserocr识别结果：{res1}')

# 识别处理后验证图片对象
res2 = pytesseract.image_to_string(image3)
print(f'pytesseract识别结果：{res2}')

'''
输出：
tesserocr识别结果：FocZ
pytesseract识别结果：FocZ
'''
```

##### 单字符图片验证码

单字符图片验证码：**即图片中只有一个字符的验证码。**

虽然现在验证码图片中的字符至少都是4位起，但有些时候我们需要将验证码拆分逐一识别，这就需要识别单字符图片验证码了。各位，可能会想，相比于上面多字符验证码，单个字符应该更好处理吧，但过程恰恰相反。

![895575-20181222231625078-557633817](image/895575-20181222231625078-557633817.png)

```python
import tesserocr
import pytesseract
from PIL import Image

image = Image.open('image.png')

code1 = tesserocr.image_to_text(image)
print(f'tesserocr识别结果：{code1}')

code2 = pytesseract.image_to_string(image)
print(f'pytesseract识别结果：{code2}')

'''
输出：
tesserocr识别结果：
pytesseract识别结果：
'''
```

上面这张图就一个数字“1”，没有多余的颜色花纹和噪点，按理来说应该很好识别，但为什么tesserocr库和pytesseract库都没把它识别出来？**我猜测原因可能是，验证码图片中的字符至少都是4位起，而这些识别库会把只有1个或2个字符的识别结果当成错误识别，直接返回一个空结果。**如果需要单独识别某个字符，需要设置参数：**只针对pytesseract库**。

```python
import pytesseract
from PIL import Image

image = Image.open('image.png')

# 识别结果仅限数字0123456789
code1 = pytesseract.image_to_string(image, config='--psm 6 --oem 3 -c tessedit_char_whitelist=0123456789')
print(f'pytesseract识别结果：{code1}')

# 识别结果仅限大小写字母
code2 = pytesseract.image_to_string(image, config='--psm 6 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz')
print(f'pytesseract识别结果：{code2}')

'''
输出：
pytesseract识别结果：1（识别正确）
pytesseract识别结果：l（识别错误，因为识别结果仅限大小写字母，而小写字母l与1最相近）
拓展：参数中还可以设置语言类型，lang='eng'，代表英语；lang='chi_sim'，代表简体中文。
'''
```

我这里选择的是**中规中矩比较好识别的验证码，OCR才能成功识别**。但对于**字符有扭曲、变形的验证码，使用OCR去识别成功率就很低了**，这就**需要软件将验证码字符进行切割处理为像素块来识别**，类似于下图，这里就不介绍了。**总的来说，OCR的识别成功率并不高**。

![QQ截图20200412161741](image/QQ截图20200412161741.png)

##### 

### 滑块验证码

##### 滑块验证码简介

普通图片验证码：即**方形缺口的图片验证码，将图片拖动至缺口位置即可验证成功**。

![QQ截图20200412164601](image/QQ截图20200412164601.png)

##### 网站验证分析

经过分析，当前网站的**验证方式就是核验滑块的移动距离**。**若移动距离等于滑块到缺口的距离，则验证成功，否则就验证失败。**

![QQ截图20200412165924](image/QQ截图20200412165924.png)

当验证成功以后，访问网站的URL就会带上滑块的位移距离。

![QQ截图20200412170719](image/QQ截图20200412170719.png)

既然这样，我们就直接识别大背景图中白色缺口所在位置即可。因为是最终需要的是位移距离，因此问我们**只需要知道白色缺口的横坐标，即下图红线的长度**。

![下载](image/下载.png)

##### 像素点比对

```python
from PIL import Image

# 打开图片对象
image1 = Image.open('image.png')
# 白色像素点个数
count = 0
# 像素点遍历方式：从上往下，从左往右
# 遍历图片的X轴
for x in range(0, image1.size[0]):
    # 遍历图片的Y轴
    for y in range(0, image1.size[1]):
        # 获取当前坐标色素点的RGB值
        color = image1.load()[x, y]
        # 白色的RGB值(255,255,255)，但颜色识别会有误差，因此认为RGB值不小于(245,245,245)即为白色
        if color[0] >= 245 and color[1] >= 245 and color[2] >= 245:
            count +=1
        # 当连续出现25个白色像素点时，则认为找到白色方块缺口
        else:
            if count > 0:
                count -=1
        if count > 25:
            break
    if count > 25:
        break

# 输出X轴的横坐标
print(f'白色缺口横坐标：{x}')        # 白色缺口横坐标：153
```

### 缺口验证码

缺口验证码：**拼图存在缺口的图片验证码，将滑块的凹凸处拖动至缺口的凹凸处即可验证成功。**

滑块验证码相对来说还比较好识别，只要你识别到了多个连续的白色像素点，就基本上找到了缺口的位置，但带缺口的验证码的就不是那么容易处理了。**因为涉及到的图像处理会更复杂，而且破解这种缺口验证码的方法，拿去破解其他缺口验证码就可能不管用了。**

##### OpenCV视觉库

OpenCV是一个用C++语言编写基于BSD许可（开源）发行的跨平台计算机视觉库，拥有丰富的常用图像处理函数，能够快速的实现一些图像处理和识别的任务，同时可以运行在Linux、Windows、Android和Mac OS操作系统上，并提供了Python、Ruby、MATLAB等语言的接口，从而使得图像处理和图像分析变得更加易于上手，让开发人员更多的精力花在算法的设计上。

**whl文件安装法**：先去官网https://www.lfd.uci.edu/~gohlke/pythonlibs/#opencv，下载相应Python版本的OpenCV的whl文件，然后在whl文件所在目录下使用命令进行安装即可。

![20180324105938996](image/20180324105938996.png)

```
pip install opencv_python‑3.4.1‑cp36‑cp36m‑win_amd64.whl
```

**包命令安装法**：直接通过包命令进行安装。

```
pip install opencv-python
```

**导入方法**：注意安装库的名称为 `opencv-python`，导入模块的名称为 `cv2`.

```
import cv2
```

**基本库函数**：列举一些需要用的基本库函数。

```python
# cv2.imread()接口读图像，读进来直接是BGR格式，不是我们最常见的RGB格式，数据格式在0~255，颜色肯定有区别。
cv2.imread(filepath, flags)     #读入一张图像
    filepath：要读入图片的完整路径（可以是绝对路径或者相对路径，路径中不能出现中文）
    flags：图像的通道和色彩信息
    	# flag = -1, 8位深度，原通道
        # flag = 0， 8位深度，1通道（灰度图（单通道））
        # flag = 1， 8位深度，3通道（默认为1，即读取为彩色图像）
        # flag = 2， 原深度， 1通道
        # flag = 3， 原深度， 3通道
        # flag = 4， 8位深度，3通道 
    cv2.IMREAD_COLOR：默认参数，读入一副彩色图片，忽略alpha通道
    cv2.IMREAD_GRAYSCALE：读入灰度图片
    cv2.IMREAD_UNCHANGED：顾名思义，读入完整图片，包括alpha通道

cv2.imshow(wname, img)     #显示图像
    wname：显示图像的窗口的名字
    img：显示的图像（imread读入的图像），窗口大小自动调整为图片大小
# 在运行cv2.imshow后，需要使用cv2.waitKey来保持窗口的显示，否则图像会一闪而过
cv2.waitKey(delay)
	delay参数表示延迟多少毫秒。默认情况为0。当delay≤0，可以理解为延迟无穷大毫秒，就是暂停了。

cv2.imwrite(file, img, num)    #保存一张图像
	file：要保存的文件名
	img：要保存的图像。可选的第三个参数，它针对特定的格式：对于JPEG，其表示的是图像的质量，用0 - 100的整数表示，默认95。
	num：压缩级别。默认为3。

cv2.resize(image, image2, dsize)     #图像缩放：(输入原始图像，输出新图像，图像的大小)
cv2.flip(img,flipcode)              #图像翻转：flipcode控制翻转效果。
	flipcode：等于0沿x轴翻转；大于0沿y轴翻转；小于0x,y轴同时翻转
```

图像格式有许多种，例如：BGR格式、RGB格式、GRAY格式、HSV格式。

```python
cv2.imread()：读出来是像素格式，即BGR格式
Image.open()：打开来的图像格式，即RGB格式

# 不同格式之间可以相互转换
cv2.cvtColor(img,XXXXXX)      #图像颜色空间转换
	img：即cv2.imread()读入的图像
cv2.cvtColor(img,cv2.COLOR_BGR2RGB)   #格式转换：将BGR格式转换成RGB格式
cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)  #热力化：将RGB格式转换成GRAY格式，彩色图像转为热力图像
cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)  #彩色化：将GRAY格式转换成RGB格式，灰度图像转为彩色图像
cv2.cvtColor(img, cv2.COLOR_RGB2HSV)  # 模型化：将RGB格式转换为HSV颜色模型
...
```

![QQ截图20201018222643](image/QQ截图20201018222643.png)

**模板匹配**：模板就是一副已知的小图像，而模板匹配就是在一副大图像中搜寻目标，已知该图中有要找的目标，且该目标同模板有相同的尺寸、方向和图像元素，通过一定的算法可以在图中找到目标。

```
模板匹配方法：
cv2.TM_CCOEFF （系数匹配法）：1表示完美的匹配；-1表示最差的匹配。
cv2.TM_CCOEFF_NORMED（归一化系数匹配法）
cv2.TM_CCORR （相关匹配法）：该方法采用乘法操作；数值越大表明匹配程度越好。
cv2.TM_CCORR_NORMED （归一化相关匹配法）
cv2.TM_SQDIFF （平方差匹配法）：采用平方差来进行匹配；最好的匹配值为0；匹配越差，匹配值越大。
cv2.TM_SQDIFF_NORMED （归一化平方差匹配法）
```

##### 易盾验证码

易盾验证码：网易易盾推出的一款嵌入式验证码，仅需轻轻滑动完成拼图，即可完成安全验证。

![yidun1](image/yidun1.jpg)

![yidun2](image/yidun2.jpg)

![yidun3](image/yidun3.jpg)

```python
import cv2
import numpy as np
from PIL import Image, ImageDraw

# 分析出具体位置
def tell_location(path1, path2, path3):
    # 以彩色图像BGR格式读取背景图
    img_rgb = cv2.imread(path2)
    # 将背景图转为热力图
    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)
    # 以灰度图像BGR格式读取缺口图
    template = cv2.imread(path1, 0)
    # 使用归一化系数匹配法，在背景图中匹配缺口图
    res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)
    # 使用二分法查找阈值的精确值
    L = 0
    R = 1
    start = 0
    run = 1
    while run < 20:
        run += 1
        threshold = (R + L) / 2
        if threshold < 0:
            print('Error')
            return None
        # 输出满足条件的坐标
        loc = np.where(res >= threshold)
        if len(loc[1]) > 1:
            L += (R - L) / 2
        # 筛选出匹配度最高的
        elif len(loc[1]) == 1:
            start = loc[1][0]
            print('目标区域起点x坐标为：%d' % start)
            break
        elif len(loc[1]) < 1:
            R -= (R - L) / 2
    distance = int(start)
    draw_line(distance, path2, path3)
    # 通过跟踪发现，最终的轨迹落点x轴位置会大10px
    return distance + 10

 # 绘制一条竖线标记位置，方便查看效果
def draw_line(x, path2, path3):
    img = Image.open(path2)
    img_draw = ImageDraw.Draw(img)
    img_draw.line((x, 0, x, img.size[1]), 'red')
    img.save(path3)

if __name__ == '__main__':
    # 小缺口图
    path1 = './yidun1.jpg'
    # 大背景图
    path2 = './yidun2.jpg'
    # 处理后图
    path3 = './yidun3.jpg'
    # 调用方法
    tell_location(path1, path2, path3)
'''
输出：
目标区域起点x坐标为：215
'''
```

##### 拼图验证码

接下来，换一种拼图验证码，直接使用上面的方法可能就不管用了，识别结果就会出现偏差，红线并没有到缺口位置：

![image1](image/image1.jpg)

![image2](image/image2.jpg)

![image3](image/image3.jpg)

**这时先不忙寻找新的方法，既然是识别结果出现了偏差，那我们是否可以将图片中影响识别的点给抹除掉，将需要识别的点给凸显出来。看下验证码，缺口图和背景图的缺口位置都存在着明显的白色轮廓，根据这些白色像素点结合上面的二值化处理方法，我们就可以将整个轮廓凸显出来，再使用上面的方法就可以达到很好的识别效果。**

![image4](image/image4.png)

![image5](image/image5.png)

![image6](image/image6.png)

```python
import cv2
import numpy as np
from PIL import Image, ImageDraw

# 二值化方法
def binary(path1, path2):
    image1 = Image.open(path1)
    img_draw = ImageDraw.Draw(image1)
    for y in range(0, image1.size[1]):
        for x in range(0, image1.size[0]):
            all = image1.load()[x, y][0] + image1.load()[x, y][1] + image1.load()[x, y][2]
            # 设定阈值为220，大于220画为白色点，小于220画为黑色点
            if all // 3 > 220:
                img_draw.point((x, y), (255, 255, 255))
            else:
                img_draw.point((x, y), (0, 0, 0))
    image1.save(path2)

# 分析出具体位置
def tell_location(path1, path2, path3):
    # 以彩色图像BGR格式读取背景图
    img_rgb = cv2.imread(path2)
    # 将背景图转为热力图
    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)
    # 以灰度图像BGR格式读取缺口图
    template = cv2.imread(path1, 0)
    # 使用归一化系数匹配法，在背景图中匹配缺口图
    res = cv2.matchTemplate(img_gray, template, cv2.TM_CCOEFF_NORMED)
    # 使用二分法查找阈值的精确值
    L = 0
    R = 1
    start = 0
    run = 1
    while run < 20:
        run += 1
        threshold = (R + L) / 2
        if threshold < 0:
            print('Error')
            return None
        # 输出满足条件的坐标
        loc = np.where(res >= threshold)
        if len(loc[1]) > 1:
            L += (R - L) / 2
        # 筛选出匹配度最高的
        elif len(loc[1]) == 1:
            start = loc[1][0]
            print('目标区域起点x坐标为：%d' % start)
            break
        elif len(loc[1]) < 1:
            R -= (R - L) / 2
    distance = int(start)
    draw_line(distance, path2, path3)
    # 返回识别距离
    return distance

 # 绘制一条竖线标记位置，方便查看效果
def draw_line(x, path2, path3):
    img = Image.open(path2)
    img_draw = ImageDraw.Draw(img)
    img_draw.line((x, 0, x, img.size[1]), 'red')
    img.save(path3)

if __name__ == '__main__':
    # 原小缺口图
    original1 = './image1.jpg'
    # 原大背景图
    original2 = './image2.jpg'
    # 处理后小缺口图
    path1 = './image4.png'
    # 处理后大背景图
    path2 = './image5.png'
    # 处理后图
    path3 = './image6.png'
    # 二值化处理原图
    binary(original1, path1)
    binary(original2, path2)
    # 调用方法识别处理后的图
    tell_location(path1, path2, path3)
'''
输出：
目标区域起点x坐标为：83
'''
```

除了结合使用前面的方法来识别图片，自己也可以写一种方法来识别图片，比如通过轮廓定位：

![image1_1](image/image1_1.jpg)

![image2_1](image/image2_1.jpg)

![image3_1](image/image3_1.jpg)

```python
from PIL import Image, ImageDraw

# 得出识别距离
def dis(path1, path2):
    '''
    :param path1: 缺口图
    :param path2: 背景图
    :return: 识别距离
    '''
    # 缺口图
    # 缺口图白色像素点列表
    white = []
    image1 = Image.open(path1)
    for y in range(0, image1.size[1]):
        # 缺口图的最大宽度为60
        x_min = 60
        x_max = 0
        for x in range(0, image1.size[0]):
            all = image1.load()[x, y][0] + image1.load()[x, y][1] + image1.load()[x, y][2]
            if all // 3 > 235:
                if x < x_min:
                    x_min = x
                if x > x_max:
                    x_max = x
        # 将每行最左边和最右边的白色点存储到列表
        if x_min != 60 and x_max != 0:
            white.append([x_min, y])
            white.append([x_max, y])
    # 筛选所有白点横坐标
    white_x = [item[0] for item in white]
    # 从左至右，从上至下，第一个白点x坐标减最小x坐标的距离
    white_fir = white_x[0] - min(white_x)
    # 背景图
    # 背景图的白色点列表
    white_bg = []
    image2 = Image.open(path2)
    for y in range(0, image2.size[1]):
        for x in range(0, image2.size[0]):
            all = image2.load()[x, y][0] + image2.load()[x, y][1] + image2.load()[x, y][2]
            if all // 3 > 235:
                # 将所有识别的白点存储到列表
                white_bg.append([x, y])
    # 遍历背景图白点列表
    for bg in white_bg:
        # 设置容错点数为7（点数越高，准确率越低，反之则越高，若为0，可能匹配不到，这和识别的白点有关）
        points = 7
        # 从第二个点遍历缺口图白点列表
        for i in range(1, len(white)):
            # 缺口图第一白点和后面所有白点的x轴差值,y轴差值
            fir_dif = [white[i][0] - white[0][0], white[i][1] - white[0][1]]
            # 结合背景图出现的白点，结合差值计算理论上可能出现的白点
            theory = [bg[0] + fir_dif[0], bg[1] + fir_dif[1]]
            # 理论白点不出现在背景图的实际白点中，容错点减一
            if theory not in white_bg:
                points -= 1
            # 当容错点为0或负数，则该点不是识别轮廓上的点
            if not points:
                break
            # 能运行到遍历结束，说明该点对应轮廓上的第一个白点
            if i == len(white) - 1:
                # 第一个白点横坐标减去轮廓第一个白点x坐标减最小x坐标的距离就是位移距离
                distance = bg[0] - white_fir
                print(f'识别位移距离：{distance}')
                return distance

# 绘制一条竖线标记位置，方便查看效果
def draw_line(x, path2, path3):
    img = Image.open(path2)
    img_draw = ImageDraw.Draw(img)
    img_draw.line((x, 0, x, img.size[1]), 'red')
    img.save(path3)

if __name__ == '__main__':
    # 原小缺口图
    original1 = './image1.jpg'
    # 原大背景图
    original2 = './image2.jpg'
    # 处理后图
    original3 = './image3.jpg'
    # 得出距离
    x = dis(original1, original2)
    if x:
        draw_line(x, original2, original3)
    else:
        print('未能有效识别...')
'''
输出：
识别位移距离：185
'''
```

##### 极验验证码

极验验证码：**一种用于区分自然人和机器人的验证服务。**

极验验证码相比缺口验证码的验证流程，还添加其他情况，验证更加严格：

1. **验证失效**：当频繁滑动极验验证码时，会偶尔出现“怪物吃掉拼图”、“请重新验证”等验证失效的情况。
2. **时间限制**：极验验证码生成时，若没有及时验证，即使后面验证通过，也会要求重新再验证一次。
3. **轨迹验证**：在拖动滑块时，会记录并上传滑块的移动轨迹，服务器会分析判定是否为人类行为还是机器行为。

![QQ截图20200412175446](image/QQ截图20200412175446.png)

**破解极验思路**：这里就只先讲解一下破解极验的思路，因为操作要用到Selenium自动化测试工具，因此具体的破解代码就放到[爬虫13-Selenium自动化测试工具](爬虫13-Selenium自动化测试工具.md)中再详细讲解。

1. **访问登录页面，确保必要的元素加载完成。**
2. 点击**按钮周围**节点，获取**不带缺口**的验证码。

![QQ截图20200412190423](image/QQ截图20200412190423.png)

3. 再点击**按钮**节点，获取**带缺口**的验证码。

![QQ截图20200412175446](image/QQ截图20200412175446.png)

4. 先将原图和有滑块的图进行像素对比，找到如图所标的两点位置，可以从右向左找到右边点的位置。

   ![QQ截图20200412175446](image/QQ截图20200412175446.png)

5.假如每个小方块就是⼀个像素点，我们从最右边的像素点1开始对比像素点，再对比像素点2第⼀列对比完再对比第⼆列，直到找到点2的位置(grap2)；然后寻从中间(left_start)的像素点1开始对比，直至找到点1的位置(grap1)；然后计算出两点之间的距离，就知道滑块应该滑动距离。

![QQ截图20200413221645](image/QQ截图20200413221645.png)

6.模拟人类滑动，所以我们在滑动的时候先分段加速，后分段减速的方式进行滑动。最后，破解极验验证码。