# 网络爬虫

### 网络爬虫简介

##### 网络爬虫定义

**网络爬虫**（`web crawler`），又称网络蜘蛛（`spider`）、网络机器人，简称**爬虫**，**是一组按照一定规则采集并存储网络信息的自动化程序**。

##### 应用领域

对于大多数的公司来说，及时的获取行业相关数据是企业生存的重要环节之一，然而行业数据的匮乏是其与生俱来的短板，合理的利用爬虫来获取数据并从中提取出有商业价值的信息是至关重要的。当然爬虫还有很多重要的应用领域，下面列举了其中的一部分：

1. 搜索引擎
2. 新闻聚合
3. 社交应用
4. 舆情监控
5. 行业数据

##### 合法性探讨

1. 网络爬虫领域目前还属于拓荒阶段，虽然互联网世界已经通过自己的游戏规则建立了Robots协议（网络爬虫排除标准)，但部分法律还在建立和完善中，也就是说，这个领域暂时还是灰色地带。
2. “法不禁止即为许可”，如果爬虫就像浏览器一样获取的是前端显示的数据（网页上的公开信息），而不是网站后台的私密敏感信息，就不太担心法律法规的约束。
3. 在爬取网站的时候，需要限制自己的爬虫遵守Robots协议，而且要尊重网站的知识产权。如果违反了这些规定，在打官司的时候败诉几率相当高。

### 网页基础

##### 网页解析流程

**超链接**：指**从一个网页指向一个目标的连接纽带**，这个目标可以是另一个网页，也可以是当前网页上的不同位置，还可以是一张图片，一个电子邮件地址，一个文件，甚至是一个应用程序。

**超文本**：**用超链接将不同空间的信息组织在一起的网状文本**，其中可以包含许多元素，比如文字、图片、链接等。

**HTML**：**超文本标记语言，它包括一系列标签，通过这些标签可以将网络上的文档格式统一**。超文本格式有很多，最常用的格式就是超文本标记语言。

**浏览器**：**解析网络上文档格式中的HTML代码，并输出展示解析后的内容**，这也是浏览器的功能之一。

**网页**：通过**超文本提供网页内容**和**超文本标记语言来规范网页展示**就形成了浏览器中展示的网页。

打比方，超链接就像是一个“指路牌”，指向下一个目标地【**单一指向**】；超文本就像“公路”，上面有许许多多的“指路牌”（超链接）、“汽车”（元素）【**集合**】；HTML 就是“交通规则”，它规范了道路上的一切事物的所在位置【**通用规则**】。

总的来说，**网页就是将超文本经过HTML格式统一提交给浏览器解析后得到的结果**。网页的源代码就是 HTML 处理超文本后的结果，也可以说是 HTML 代码，查看方式：

1. 在网页空白处，鼠标右键，点击`查看网页源代码`。
2. 打开网页，直接 `Ctrl+U`，查看网页源代码。
3. **注意：按 `F12` 或 `Ctrl+Shift+I` 在 `Elements` 看到的网页代码是加载过后的代码，不是源代码。**

##### URL

在网络上，**每一项信息资源都有统一的且在网上唯一的地址**，该地址就叫**URL（`Uniform Resource Locator`,统一资源定位符）**，就是指**网络地址**。

![QQ截图20200107225421](image/QQ截图20200107225421.png)

这幅蜡笔小新图片的网络地址是：`https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1578418740765&di=6547dbf458d375b8f20d2f8ef11b322d&imgtype=0&src=http%3A%2F%2Fuploads.5068.com%2Fallimg%2F1803%2F134RJ2I-5.jpg`，因为图片格式资源，所以结尾是 `.jpg`。

##### HTTP 协议

**网页上看到的内容通常是浏览器执行HTML语言得到的结果，而 HTTP 就是传输 HTML 数据的协议。**

HTTP：`Hyper Text Transfer Protocol`，超文本传输协议。

HTTPS：`Hyper Text Transfer Protocol over Secure Socket Layer`，HTTP 加⼊ SSL 层，传输内容通过 SSL 加密，保证数据传输安全和网站真实性。

### 请求

##### 请求方式

浏览器想要获取网页数据在请求服务器的时候，会有多种请求方式，但主要是以下两种：

`GET` 请求：请求的参数直接在URL里，最多只有1024字节。 

`POST` 请求：请求的参数⼀般通过表单提交，不会出现在URL里，大小没有限制。

![QQ截图20200114225501](image/QQ截图20200114225501.png)

##### 请求头参数

请求头参数：`Request Headers` ，简称**请求头**，里面**包含了请求网页页面的参数**。

查看方式：各种抓包工具、谷歌浏览器（网页中鼠标右键——查看——Network——点击加载文件——Headers）

![QQ截图20200114230700](image/QQ截图20200114230700.png)

**Accept**：**接收数据类型**，指定客户端可以接受的内容类型，比如文本，图片等，内容的先后排序表示客户端接收的先后次序，每种类型之间用逗号隔开。 其中，对于每⼀种内容类型在分号 `;` 后面会加⼀个 `q=0.6` 这样的 `q` 值，表示该种类型被客户端喜欢接受的程度，如果没有表示 `q=1`，数值越高，客户端越喜欢这种类型。**爬取数据时，将想要找的文字、图片放在前面，其他的放在后面，最后⼀定要加上 `q` 值。**

```
Accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9

textxml,textshtml：文本类型，斜杠后表示⽂档的类型，xml或者shtml

application/xml,application/xhtml+xml：应用类型，后⾯表示文档类型,比如flash动画，excel表格等等

imagegif,imagex-xbitmap：图片类型，表示接收何种类型的图片

/：表示接收任何类型，但是这⼀条⼀般写在最后，表示优先接收前⾯规定的类型，然后再加载其他类型。
```

**Accept-Encoding**：**接收编码类型**，即网络压缩格式。 

```
Accept-Encoding: gzip, deflate

gzip：现在常用的网络压缩格式

deflate：⼀种过时的网络压缩格式
```

**Accept-Language** ：**可以接受语言类型**，⼀般就接收中文和英文，参数值规范和 accept的很像。

``` 
Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4 

zh-CN：中文简体⼤陆

zh：其他中⽂

en-US：英语美语 

en：其他英语
```

**Accept-Charset** ：**表单数据的字符集类型**，若没有定义，则默认值为 `unknown`。如果服务器没有包含此种字符集，就无法正确接收。⼀般情况下，在爬⾍时不定义该属性。

```
Accept-Charset：gb2312,gbk;q=0.7,utf-8;q=0.7,*;q=0.7
```

**Cache-Control**：**缓存控制**，指定了服务器和客户端在交互时遵循的缓存机制，即是否要保留缓存页面数据。 ⼀般在使用浏览器访问时，都会在计算机本地留下缓存页面，相当于是浏览器中的页面保存和下载选项。**但是爬虫就是为了从网络上爬取数据，所以几乎不会从缓存中读取数据，所以在设置的时候要侧重从服务器请求数据而非加载缓存**。 

```
no-cache：客户端告诉服务器不读取缓存，只向服务器发起请求。

no-store：请求和响应都禁止缓存，即不存储。 

max-age=0：表示当访问过此网页后的多少秒内再次访问，只加载缓存，而不去服务器请求，爬虫⼀般就写0秒。

⼀般爬虫就使用以上几个参数，其他的参数都是接受缓存的，所以就不列出了。
```

**Pragma**： 防止页面被缓存, 和 cache-control 类似的⼀个字段，**⼀般爬虫都写成 no-cache**。

**Connection**：**保持长连接**，由于http请求是无记忆性的，长连接指的是在客户端和服务端之间建立⼀个通道，方便两者之间进行多次数据传输，而不用来回传输数据。**爬虫⼀般都建立⼀个长连接**。

```
Connection:keep-alive

keep-alive：表示希望保持畅通来回传输数据

close：表示不想建立长连接，在操作完成后关闭链接
```

**Proxy-Connection**：**代理服务器保持长链接**，数据从客户端到代理服务器和从代理服务器到被请求的服务器之间，如果存在信息差异的话，会造成信息请求不到，但是在⼤多数情况下，都还是能够成⽴的。

**Cookie** ：**跟踪浏览器用户的访问前后路径**，Cookie是客户机在请求服务器时，服务器返回的⼀个键值对样的数据给浏览器，**下⼀次浏览器再访问这个域名下的网页时，就需要携带这些键值对数据在 Cookie中**。 在爬虫时，**根据前次访问得到 cookie数据，然后添加到下⼀次的访问请求头中**，是**一个比较关键的字段**。

```
Cookie:ASP....=...
```

**Host**：**服务器网站域名**，爬虫时可以从访问的 URL 中获得。

```
Host:www.主机域名.com
```

**Referer**：**上一层网页的 URL**。由于**http协议的无记忆性**，服务器可从这里了解到客户端访问的前后路径，并做⼀些判断，**如果后⼀次访问的 URL 不能从前⼀次访问的页面上跳转获得， 在⼀定程度上说明了请求头有可能伪造**。个别爬虫需要加上该参数。

```
Referer:https://www.上一层网页URL.com?...
```

**DNT**： **禁止第三方网站追踪**，主要是用来保护浏览器用户隐私的，用户可以检测到跨站跟踪、cookie 跟踪等等。 在爬⾍时⼀般都是禁止的。**数字1代表禁止追踪，0代表接收追踪，null 代表空置，没有规定**。

**If-Modified-Since**：**指定日期**，只有当所请求的内容在指定的日期之后又经过修改才返回它，否则返回304。其目的是为了提高访问效率。在爬虫时，一般不设置这个值，**而在增量爬取时才设置⼀个这样的值，用以更新信息**。

**Authorization**：当客户端接收到来自WEB服务器的 WWW-Authenticate 响应时，该头部来回应自己的身份验证信息给WEB服务器。主要是授权验证，确定符合服务器的要求。在爬虫时，按需而定。

**User-Agent**：**用户代理**，服务器从此处知道客户端的操作系统类型和版本，电脑CPU类型，浏览器种类版本，浏览器渲染引擎，等等。这是**爬虫中最重要的⼀个请求头参数**，所以爬虫⼀定要有，如果没有，很容易被服务器识别并封禁。

```
# 浏览器Firefox版本52.0
User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0

# 浏览器Chrome版本52.0.2743.11或浏览器Safari版本537.36，前面是windows大概率为Chrome
User-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like 
Gecko) Chrome/52.0.2743.116 Safari/537.36
```

##### 标准的爬虫请求头

```
"Accept": "texthtml,applicationxhtml+xml,applicationxml;q=0.9,imagewebp,/;q=0.8”,
"Pragma": "no-cache", 
"Cache-Control": "no-cache", 
"Proxy-Connection": "keep-alive", 
"DNT": "1", 
"Accept-Encoding": "gzip, deflate, sdch", 
"Accept-Language": "zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4", 
"Accept-Charset": "gb2312,gbk;q=0.7,utf-8;q=0.7,*;q=0.7",
"Referer": "...", 
"User-Agent": "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like 
Gecko) Chrome/52.0.2743.116 Safari/537.36", 
```

### 响应

##### HTTP 状态码

**客户端发送请求，服务器就会返回响应，响应就包括 HTTP 状态码和数据两部分。**

**HTTP 状态码(`HTTP Status Code`)**：表示网页服务器响应状态的3位数字代码，按首位数字分成五个类别，共包含100多种状态码，覆盖了绝大部分可能遇到的情况。每一种状态码都有标准的（或者约定的）解释，客户端只需查看状态码，就可以判断出发生了什么情况。

![QQ截图20200118230729](image/QQ截图20200118230729.png)

常见的状态码：

```
1xx：相关信息（API 不需要1xx状态码，下面介绍其他四类状态码的精确含义。）

2xx：操作成功
GET: 200 OK：请求成功。
POST: 201 Created：表示生成了新的资源。
PUT: 200 OK
PATCH: 200 OK
DELETE: 204 No Content：表示资源已经不存在。

3xx：重定向
301 Moved Permanently：永久重定向。
302 Move Temporarily：暂时重定向。

4xx：客户端错误
400 Bad Request：服务器不理解客户端的请求，未做任何处理。
401 Unauthorized：用户未提供身份验证凭据，或者没有通过身份验证。
403 Forbidden：用户通过了身份验证，但是不具有访问资源所需的权限。
404 Not Found：所请求的资源不存在，或不可用。
405 Method Not Allowed：用户已经通过身份验证，但是所用的 HTTP 方法不在他的权限之内。
410 Gone：所请求的资源已从这个地址转移，不再可用。
415 Unsupported Media Type：客户端要求的返回格式不支持。
422 Unprocessable Entity ：客户端上传的附件无法处理，导致请求失败。
429 Too Many Requests：客户端的请求次数超过限额。

5xx：服务器错误（一般来说，API 不会向用户透露服务器的详细信息，所以只要两个状态码就够了。）
500 Internal Server Error：客户端请求有效，服务器处理时发生了意外。
503 Service Unavailable：服务器无法处理请求，一般用于网站维护状态。
```

##### 响应头参数

请求头参数：`Response Headers` ，简称**响应头**，里面**包含了服务器响应的参数**。

查看方式：各种抓包工具、谷歌浏览器（网页中鼠标右键——查看——Network——点击加载文件——Headers）

![QQ截图20200118231047](image/QQ截图20200118231047.png)

**Content-Encoding**：**指定响应内容的编码**。

```
Content-Encoding: gzip

gzip：现在常用的网络压缩格式
```

**Content-Type**：**内容类型**。此项参数**针对于 POST 请求，因为 POST 请求体有内容，GET请求体为空**。

```
application/x-www-form-urlencoded：表单数据 

multipart/form-data：表单⽂件上传 

application/json：序列化json数据 

text/xml：xml数据
```

**Date**： **响应产生的时间**。因为**北京时间是东八区，换算成北京时间还需要加上八个小时**。

```
Date: Sat, 18 Jan 2020 14:40:05 GMT
```

**Server**：包含了服务器的信息，名称，版本号等。

```
Server: Microsoft-IIS/8.5
```

**Set-Cookie**：设置Cookie，即告诉浏览器需要将此内容放在 Cookies 中，下次请求携带 Cookies 请求。

**Last-Modified**：指定资源的最后修改时间。

**Expires**：指定响应的过期时间，将内容更新到缓存中，再次访问时，直接从缓存中加载，降低服务器负载，缩短加载时间。

