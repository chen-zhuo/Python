# 分布式爬虫

前面提到过，一个爬虫只运行在一个主机上，就算效率再怎么高，面对需要采集量巨大的任务时，仍然会显得力不从心。**假如，我们将爬虫分布到多台主机上，再共享一个消息队列，那么采集效率就会翻倍，这就是“分布式爬虫”。**

## 技术原理

### 分布式原理

Scrapy框架中，每个爬虫都有一个自己的request队列（消息队列）和一个自己的调度器，当爬虫启动以后，调度器从消息队列中获取request给爬虫进行爬取。

![QQ截图20200918000607](image/QQ截图20200918000607.png)

如果两个调度器同时从消息队列里面取 Request ，在带宽足够、正常爬取且不考虑队列存取压力的情况下，那么其爬取效率会翻倍。这样，调度器可以扩展多个，下载器也可以扩展多个，**而爬取队列 Queue 必须始终为1个，也就是所谓的共享爬取队列。这样才能保证调度器从队列里调度某个 Request 后，其他调度器不会重复调度此 Request ，就可以做到多个调度器同步爬取。这就是分布式爬虫的基本雏形。**

![QQ截图20200920021917](image/QQ截图20200920021917.png)

我们需要做的就是在多台主机上同时运行爬虫任务协同爬取，而协同爬取的前提就是共享爬取队。**这样各台主机就不需要各自维护爬取队列，而是从共享爬取队列存取 Request。但是各台主机还是有各自的调度器和下载器，所以调度和下载功能分别完成。**如果不考虑队列存取性能消耗，爬取效率还是会成倍提高。

### MQ消息队列

前面提到，多线程爬虫、协程爬虫在很大程度上提升了采集的效率，这两种爬虫都使用了相同的“策略”，**将所有要爬取的链接先获取下来，用列表存储，再启动爬虫程序，不重复的获取链接，省掉了其他爬虫等待链接的时间和本身的闲置时间，因此能成倍提升采集效率。**这里存储链接的列表，就可以称之为**消息队列**。

消息队列：**简称MQ，是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。**

消息队列特点：**阅后即焚**。消息队列里面的消息被使用后就被销毁了。

消息队列作用：在高并发环境下，由于来不及同步处理，请求往往会发生堵塞，**通过使用消息队列，我们可以异步处理请求，从而缓解系统的压力**。

#### 消息队列模型

生产者(producer)：**发送消息的程序。**

![20170524102259570](image/20170524102259570.png)

队列(queue)：**存储消息的队列。** 一个队列只受到主机的内存和磁盘的限制，它实际上是个大的消息缓冲区。

![20170524104231217](image/20170524104231217.png)

消费者(consumer)：**等待接收消息的程序**。

![20170524104158185](image/20170524104158185.png)

消息流：**生产者只管创建消息并发布到队列中，消费者只管监听或使用队列中的消息。**

![1436447-20181121135142706-7726795](image/1436447-20181121135142706-7726795.png)

?> 提示：多个生产者可以发送消息到一个队列，多个消费者可以监听或使用同一个队列中的消息。

#### Queue队列

python中有支持队列的两个标准库：进程队列模块 `multiprocessing`、线程队列模块 `queue`（两个模块的用法一模一样）

进程队列模块 `multiprocessing`：**用于多进程，它通过管道以及锁和信号量机制来协调多个进程，数据可以在多进程之间共享同一个变量的数据。**

```python
import multiprocessing

# 创建一个进程队列
q = multiprocessing.Queue()
```

线程队列模块 `queue`：**用于多线程，它可以指定缓冲区大小的阻塞队列，但数据无法在多个进程之间共享。**

```python
import queue

# 创建线程队列，Queue先进先出模式
q1 = queue.Queue()

# empty()判断队列是否为空
print(q1.empty())	# True
# 获取队列q的长度
print(q1.qsize())	# 0

for i in range(3):
	# 向队列q中插入变量数据i
    q1.put(i)

# empty()判断队列是否为空
print(q1.empty())	# False
# 获取队列q的长度
print(q1.qsize())	# 3

# get()获取数据，每次get只能取一个数据
print(q1.get())  # 0
print(q1.get())  # 1
print(q1.get())  # 2


# 创建线程队列，LifoQueue先进后出模式
# maxsize参数表示队列中能存放的数据个数的上限；默认等于0，表示队列大小没有限制。
q2 = queue.LifoQueue(maxsize=4)

# 插入数据0，1，2，3后，消息队列数据达到上限，发生阻塞，不会执行下面的print语句。
for i in range(5):
    q2.put(i)	
print('程序结束')

# 队列q2中一边插入数据，一边消费数据，所以不会发生阻塞，可以执行下面的print语句。
for i in range(5):
    q2.put(i)
    print(q2.get())	
print('程序结束')	
'''
输出：4 3 2 1 0 程序结束
解释：put(i)插入一次数据，get()获取一次数据，数据量不会达到队列上限4，能执行print语句。
'''
```

?> 提示：`queue` 和 `multiprocessing` 模块，两者 `Queue` 队列的 `get`、`put`、`empty`、`qsize` 等方法名称是相同的。

#### Redis消息队列

**Redis是时下比较火的内存数据库，以简单高效著称，具有丰富的数据类型，常用于缓存数据，也支持队列queue，我们可以将Redis作为message broker（消息中间人）。**

Redis目前只能实现简单的消息队列功能，它所具有的优点：

- 极低延迟：得益于Redis本身的高效，消息可以极低延迟传递。
- 上手容易：只需组合使用两三个命令，即可完成消息传递。
- 查看便利：可以便利地查看队列内容；利用 `MONITOR` 命令甚至可以实时监控消息入队和出队。
- 单线程锁：**Redis本身是一个单线程的，相当于所有操作都有一把天然的排他锁，因此我们不用担心在并发下同一条消息会传递给多个使用者**。

##### 可靠消息队列

可靠消息队列：**由两个列表组成，一个存储待处理（`pending`）的消息，另一个存储处理中（`processing`）的消息。**

可靠消息队列运行流程：

1. **生产者将所有任务添加至待处理列表里面；**
2. **消费者从待处理列表里面获取任务，并将该任务添加至处理中列表；**
3. **消费者成功处理任务后，再将处理中列表里面的任务删除。**

使用可靠消息队列的优势在于，可以防止处理异常，而导致任务丢失。详情请阅读：《DataBase》中的《Redis-消息队列》

##### 启动配置服务

首先确保本机已经安装了Redis，接着修改Redis的配置文件`redis.windows.conf`，方便使用：

1. 注释绑定，在 `bind 127.0.0.1` 前面加上一个注释，允许其他IP能连接Redis。

![QQ截图20200917224556](image/QQ截图20200917224556.png)

2. 设置密码，取消 `requirepass` 前面的注释，在后面加上自己的密码 。

![QQ截图20200917223824](image/QQ截图20200917223824.png)

3. 配置启动，为了让修改的配置起作用，在命令行通过配置文件来启动Redis。

```
redis-server "Redis安装路径\redis.windows.conf"
```

![QQ截图20200917225122](image/QQ截图20200917225122.png)

4. 连接Reids，再启一个命令行，通过密码来连接Redis进行操作。

```
方法一：连接时，通过密码进行身份验证
redis-cli -a 密码

方法二：连接后，通过密码进行身份验证
redis-cli
auth 密码
```

![QQ截图20200917230443](image/QQ截图20200917230443.png)

##### 任务处理

**添加任务**：向 Redis 里面添加需要处理的任务，任务包含在 `Task.txt` 文件当中：

```python
# 导入Redis模块
from redis import StrictRedis
# 连接局域网内IP为192.168.0.3的机器上密码设置为123456的Redis的0号数据库
client = StrictRedis(host='192.168.0.3', port=6379, db='0', password='123456')
# 读取任务文件
Task.txtwith open('Task.txt', 'rb') as f:    
    for message in f.readlines():    
        # 通过lpush命令将任务添加到pending待处理列表左侧    
        print(client.lpush("pending", message))
```

**获取任务**：弹出 `pending` 待处理列表最右边的任务，并且将任务添加到处理中的 `processing` 任务列表的最左边。

```python
# 导入Redis模块
from redis import StrictRedis
# 连接局域网内IP为192.168.0.3的机器上密码设置为123456的Redis的0号数据库
client = StrictRedis(host='192.168.0.3', port=6379, db='0', password='None')
# 弹出pending待处理列表最右边的任务，并且将任务添加到处理中的processing任务列表中
message = client.rpoplpush('pending', 'processing')
# 开始处理任务...
```

**删除任务**：当任务成功处理完毕，再将任务从处理中的 `processing` 任务列表删除。

```python
# 任务处理完毕...
# 删除处理中的processing任务列表中从左至右与message内容相同的第一条任务
client.lrem('processing', 1, message)
```

#### RabbitMQ框架

RabbitMQ是一个专门做队列的框架，在队列方面要比redies队列性能要好，支持的功能会更多，消息的可靠性更强，且支持多种语言: Java、.NET、PHP、Python、JavaScript、Ruby、Go这些常用语言都支持。

##### RabbitMQ模型

RabbitMQ 是一个消息中间人（broker）: 它接收并且发送消息. 

可以想象一个邮局：当你把想要寄出的信放到邮筒里时，邮递员会把信件送到收信人那里。 

在这个比喻中, RabbitMQ 就是一个邮筒（接收）, 同时也是邮局（存储）和邮递员（转发） 。和邮局的主要不同点在于RabbitMQ不处理纸质信件, 而是 接收（accepts）, 存储（stores） 和转发（forwards）二进制数据块 —— 消息（messages）。

##### 安装RabbitMQ

这里给出安装步骤的参考文章 [Windows下RabbitMQ安装及配置](https://blog.csdn.net/zhm3023/article/details/82217222)。

##### 操作RabbitMQ

![1415597-20190306075858416-1490847372](image/1415597-20190306075858416-1490847372.png)

python操作RabbitMQ需要的模块有上述几种选择，我们用最简单的pika，用pip直接安装

```
pip install pika
```

因为RabbitMQ对于我来说使用不多，这里也直接给出参考文章 [Python之RabbitMQ的使用](https://www.cnblogs.com/yinsedeyinse/p/10481056.html)。

## VPS方案

### VPS技术

上面首先就提到了，分布式爬虫需要使用到多台主机，这里的主机并不是指硬件上的一台主机，也可以是虚拟主机，本着充分利用计算机资源的原则，VPS技术派上用场了。

VPS技术：**Virtual Private Server 虚拟专用服务器，将一台服务器分割成多个虚拟专享服务器的优质服务。在容器或虚拟机中，每个VPS都可选配独立公网IP地址、独立操作系统、实现不同VPS间磁盘空间、内存、CPU资源、进程和系统配置的隔离，为用户和应用程序模拟出“独占”使用计算资源的体验。VPS可以像独立服务器一样，重装操作系统，安装程序，单独重启服务器。**

**简单理解，VPS就是通过虚拟化技术隔离出来的系统。**下面的VPS都是通过**VMWare虚拟机软件**在一台物理主机的资源划分出来3个虚拟机：

![QQ截图20200920024137](image/QQ截图20200920024137.png)

既然有了许多台虚拟的主机，那么现在我们需要给每台虚拟主机分配独立的外网IP地址，不然即使划分再多主机，对于外界网络来说，就是一台主机。在一台物理主机上面有多张网卡，每台虚拟主机可配置一张有线网卡进行单独拨号，因此我们这里就可以使用VPS拨号技术了。

### VPS拨号

VPS拨号：**即VPS动态服务器，是利用宽带拨号更换IP地址，如果企业或个人需要更换IP，就可以选择拨号VPS了。**当然它并不是只能进行换IP，拨号VPS还有如下许多功能：

1. **适合用于爬虫采集**：在爬虫行业中，爬虫需要大量的进行爬行采集工作，使用免费代理IP和重启路由器这样的操作更是繁琐到不行了，此时你就考虑使用拨号vps。
2. **SEO优化类**：当下互联网的算法在不断完善，那么对于seo要求也是越来越高，一个网站想要快速的获取到有效的排名，必然少不了拨号vps；利用每一个真实有效的IP，针对不同的关键字模仿正常人的搜索，点击，浏览网页，都有有效的帮助到目标关键词的优化，从而快速获取关键字排名靠前。
3. **软件挂机**：在线客户端软件，比如QQ、YY语音（可以进频道）、旺旺等，可以增加经验值，也能让号一直在线，还可以挂一些网页游戏。
4. **加速访问**：通常拨号VPS都具有缓冲的功能，有很大的存储空间，网络出现拥堵或系统故障时，可通过拨号VPS访问目的网站，节约网络带宽、显著提升访问速度和效率。

下图中每台虚拟主机的外网地址都是不一样且不固定的。例如：

```
第一台虚拟主机的内网地址为192.168.0.36，外网地址为101.204.79.xxx
第二台虚拟主机的内网地址为192.168.0.37，外网地址为101.204.121.xx
第三台虚拟主机的内网地址为192.168.0.38，外网地址为101.204.12.xx
60秒后
第一台虚拟主机的内网地址为192.168.0.36，外网地址为101.203.79.xxx
第二台虚拟主机的内网地址为192.168.0.37，外网地址为101.203.121.xx
第三台虚拟主机的内网地址为192.168.0.38，外网地址为101.203.12.xx
```

![QQ截图20200921093550](image/QQ截图20200921093550.png)

### 桌面软件

有了服务器我们还需要软件来连接这些服务器，这里使用的软件是：[Remote Desktop Connection Manager](https://remotedesktopmanager.com/)(远程桌面管理工具)。

Remote Desktop Connection Manager能够集中管理多个远程桌面连接，并可在多个同时打开的远程面桌面间快速切换。而且即使我们重装了系统或在其他PC上也能快速载入这些常用的远程桌面。这对于管理需要定期访问每台机器（例如自动检入系统和数据中心）的服务器实验室非常有用。服务器被组织为命名组。您可以使用单个命令连接或断开连接到一个组中的所有服务器。您可以按一组缩略图查看组中的所有服务器，并在每个会话中显示实时操作。服务器可以从父组或凭据存储继承其登录设置。因此，当您更改实验室帐户密码时，只需在一个位置更改RDCMan存储的密码。通过使用（本地）登录的用户权限或X509证书使用CryptProtectData进行加密，可以安全地存储密码。

## Zookeeper方案

首先什么是zookeeper？参看在《System》当中的《ZK分布式》章节。

### kazoo库简介

**kazoo库使用纯Python实现Zookeeper协议，因此不需要安装任何额外的软件就可以直接连接Zookeeper。**

安装Kazoo也很简单，直接通过 `pip` 安装：

```
pip install kazoo
```

要开始使用 Kazoo，必须创建一个 `KazooClient` 对象并建立连接：

```python
from kazoo.client import KazooClient

zk = KazooClient(hosts='127.0.0.1:2181')
zk.start()
```

?> 默认情况下，客户端将通过默认端口(2181)连接到本地Zookeeper服务器。首先您应该确保Zookeeper在那里运行，否则start命令将一直等到其默认超时。

连接后，无论间歇性连接丢失或 Zookeeper 会话过期，客户端都将尝试保持连接。可以通过调用stop指示客户端断开连接：

```python
zk.stop()
```

### 监听状态

**客户端的常见状态可以分为三种：丢失（LOST）、连接（CONNECTED）、暂停（SUSPENDED）。**可以通过查看 `state` 属性来确定：

```python
from kazoo.client import KazooClient

zk = KazooClient(hosts='127.0.0.1:2181')
zk.start()
print(zk.state)  # CONNECTED 注释：当前处于连接状态
# 注释：KazooClient首次创建实例，它是在LOST状态。建立连接后，它转换到 CONNECTED状态。
```

当客户端状态为SUSPENDED时，如果客户端正在执行需要与其他系统达成一致的操作（例如使用Lock），它就会暂停它正在执行的操作。重新建立连接后，客户端状态为CONNECTED时，客户端可以继续执行操作。

当客户端状态为LOST时，Zookeeper 将删除任何已创建的临时节点，这将会影响所有创建临时节点（例如使用Lock），当状态再次转换为CONNECTED后，需要重新获取锁。

常见的状态转换：

- **LOST -> CONNECTED**：新连接，或之前丢失的连接正在连接。
- **CONNECTED -> SUSPENDED**：与服务器的连接丢失发生在连接上。
- **CONNECTED -> LOST**：仅当在建立连接后提供无效的身份验证凭据时才会发生。
- **SUSPENDED -> LOST**：连接恢复到服务器，但由于会话过期而丢失。
- **SUSPENDED -> CONNECTED**：丢失的连接已恢复。

针对客户端状态，通过 `KazooState` 来进行判断可以写出如下状态监听器：

```python
from kazoo.client import KazooState

def my_listener(state):
    if state == KazooState.LOST:
        # Register somewhere that the session was lost
    elif state == KazooState.SUSPENDED:
        # Handle being disconnected from Zookeeper
    else:
        # Handle being connected/reconnected to Zookeeper

zk.add_listener(my_listener)
```

?> 在使用 `kazoo.recipe.lock.Lock` 或创建临时节点时，强烈建议添加状态侦听器，以便您的程序可以正确处理连接中断或 Zookeeper 会话丢失。

### 节点CRUD

Zookeeper 有用于创建、读取、更新和删除 Zookeeper 节点（这里称为 znodes 或节点）的功能。针对的，Kazoo 添加了几个方便的方法和一个更 Pythonic 的 API。

**首先需要明白的一点就是，节点是一个抽象的事物存在于会话当中，因此节点的路径也不是真实存在的。**

#### 创建节点

Kazoo创建节点的最常用两个方法：

`ensure_path()`：递归创建节点和沿途所需路径中的任何节点，但不能为节点设置数据，只能设置 ACL。

`create()`：创建一个节点，并可以在节点上设置数据以及一个 watch 函数。它要求它的路径首先存在，除非 `makepath` 选项设置为True。

```python
# 创建一个节点
zk.ensure_path("/my/favorite")

# 创建一个带有数据的永久节点，前提是/my/favorite路径必须存在
zk.create("/my/favorite/node", b"a value")

# 创建一个带有数据的永久节点，/my/favorite路径可以不存在
zk.create("/my/favorite/node", b"a value", makepath=True)

# 创建一个带有数据的临时节点，/my/favorite路径可以不存在
zk.create("/my/favorite/node", b"a value", makepath=True, ephemeral=True)
```

?> 子节点可以被无限递归的创建。

#### 检查节点

Kazoo检查节点的最常用三个方法：

`exists()`：检查节点是否存在。

`get()`：获取节点的数据以及 `ZnodeStat` 结构中的详细节点信息。

`get_children()`：获取给定节点的子节点列表。

```python
# 判断节点
if zk.exists("/my/favorite"):
    # Do something

# 打印一个节点的版本和它的数据
data, stat = zk.get("/my/favorite")
print("Version: %s, data: %s" % (stat.version, data.decode("utf-8")))

# 列出子节点
children = zk.get_children("/my/favorite")
print("There are %s children with names %s" % (len(children), children))
```

#### 更新节点

`set()`：更新指定节点的数据，在更新数据之前需要匹配提供的节点版本，否则将引发`BadVersionError` 而不是更新。

```python
zk.set("/my/favorite", b"some data")
```

#### 删除节点

`delete()`：删除一个节点，也可以选择递归删除该节点的所有子节点。在删除节点之前需要匹配节点的版本，否则将引发 `BadVersionError` 而不是删除。

```python
zk.delete("/my/favorite/node", recursive=True)
```

### 重试连接

#### retry方法

如果 Zookeeper 服务器出现故障或无法访问，与 Zookeeper 的连接可能会中断。默认情况下，kazoo 不会重试命令，因此这些失败将导致引发异常。为了帮助解决失败，kazoo 附带了一个 `retry()` 助手，如果 Zookeeper 连接异常被触发，重试连接到Zookeeper。

```python
result = zk.retry(zk.get, "/path/to/node")
```

#### 重试函数

**某些命令可能具有独特的行为，不保证在每个命令的基础上自动重试。**例如，当使用临时和序列选项集创建一个节点，在命令成功返回之前可能会丢失连接，但该节点实际上已创建，再次运行时引发 `kazoo.exceptions.NodeExistsError`。

由于 `retry()` 方法需要调用一个函数及其参数，因此可以将运行多个 Zookeeper 命令的函数传递给它，以便在连接丢失时重试整个函数。锁实现中的这个片段显示了它如何使用重试重新运行获取锁的函数，并检查它是否已经被创建来处理这种情况：

```python
# kazoo.recipe.lock snippet

def acquire(self):
    """获取互斥锁，阻塞直到它被获取""" 
    try:
        self.client.retry(self._inner_acquire)
        self.is_acquired = True
    except KazooException:
        # if we did ultimately fail, attempt to clean up
        self._best_effort_cleanup()
        self.cancelled = False
        raise

def _inner_acquire(self):
    self.wake_event.clear()

    # 确保我们指定的节点存在
    if not self.assured_path:
        self.client.ensure_path(self.path)

    node = None
    if self.create_tried:
        node = self._find_node()
    else:
        self.create_tried = True

    if not node:
        node = self.client.create(self.create_path, self.data,
            ephemeral=True, sequence=True)
        # 去除节点的路径
        node = node[len(self.path) + 1:]
```

#### 自定义重试

有时，您可能希望为与 `retry()` 方法不同的命令或命令集设置特定的重试策略 。您可以使用您喜欢的特定重试策略手动创建 `KazooRetry` 实例：

```python
from kazoo.retry import KazooRetry

kr = KazooRetry(max_tries=3, ignore_expire=False)
result = kr(client.get, "/some/path")
```

这将重试`client.get`命令最多 3 次，并在发生时引发会话过期。您还可以使用默认行为创建一个实例，在重试期间忽略会话过期。

### 监视

**Kazoo 可以在节点上设置监视功能，该功能可以在更改或删除节点或其子节点更改时触发。**

Watchers 可以通过两种不同的方式设置：

**第一种是 Zookeeper 默认支持一次性 watch 事件样式。**这些 watch 函数会被 kazoo 调用一次，并且不接收 session 事件。使用此样式需要将 watch 函数传递给`get()`、`get_children()`、`exists()` 方法之一，当节点上的数据发生变化或节点本身被删除时，将调用传递给该方法的 watch 函数。它将传递一个 `WatchedEvent` 实例：

```python
def my_func(event):
    # 检查子节点现在情况
    pass

# 当子节点改变调用watch事件对应的my_func函数
children = zk.get_children("/my/favorite/node", watch=my_func)
```

**第二种是使用 Kazoo 包含的一个用于监视数据和子节点修改的 API。**在每次触发事件时它不需要重新设置监视，即使用此 API 注册的 Watch 函数将在每次发生更改时立即调用，或者直到函数返回 False。如果 `allow_session_lost` 设置为 `True`，则在会话丢失时将不再调用该函数。以下方法 `ChildrenWatch`、`DataWatch` 可直接在 `KazooClient` 实例上使用，并且在以这种方式使用时不需要传入客户端对象，通过实例可以直接调用，允许它们用作装饰器：

```python
@zk.ChildrenWatch("/my/favorite/node")
def watch_children(children):
    print("Children are now: %s" % children)
# Above function called immediately, and from then on

@zk.DataWatch("/my/favorite")
def watch_node(data, stat):
    print("Version: %s, data: %s" % (stat.version, data.decode("utf-8")))
```

### 命令流

**Zookeeper 3.4 及更高版本支持一次发送多个命令，这些命令将作为单个原子单元提交。他们要么全部成功，要么全部失败。事务的结果将是事务中每个命令的成功/失败结果列表。**

```python
# transaction()方法返回一个TransactionRequest实例
transaction = zk.transaction()
# 调用它的方法来排队完成事务中的命令
transaction.check('/node/a', version=3)
transaction.create('/node/b', b"a value")
# 当事务准备好发送时，调用它的commit()方法。
results = transaction.commit()
```

在上面的示例中，只要有一个命令不可用，就会失败报错。这可以用来检查特定版本的节点，节点 `/node/a` 版本必须是3，如果节点与它应该处于的版本不匹配，将不会创建 `/node/b` ，则该版本事务失败。

### 异步使用

所有异步 Kazoo API 依赖于异步方法返回的 `IAsyncResult` 对象。可以使用 `rawlink()` 方法添加回调，无论使用线程还是使用 gevent 等异步框架，该方法都可以兼容。

连接处理创建连接：

```python
from kazoo.client import KazooClient
from kazoo.handlers.gevent import SequentialGeventHandler

# 使用IHandler接口来抽象回调系统
zk = KazooClient(handler=SequentialGeventHandler())

# 立即返回
event = zk.start_async()

# 设置超时等待30秒
event.wait(timeout=30)

if not zk.connected:
    # 未连接，停止尝试连接
    zk.stop()
    raise Exception("Unable to connect.")
```

?> Kazoo 不依赖 gevents/eventlet 猴子补丁，并要求传入适当的处理程序，默认处理程序是 `SequentialThreadingHandler`。

除了 `start_async()` 之外的所有kazoo _async方法都返回一个 `IAsyncResult`实例。回调函数将传递 `IAsyncResult` 实例，并应调用其上的 `get()`方法以检索值。如果异步函数遇到错误，则此调用可能会导致引发异常。它应该被抓住并妥善处理。

例子：

```python
import sys
from kazoo.exceptions import ConnectionLossException
from kazoo.exceptions import NoAuthException

def my_callback(async_obj):
    try:
        children = async_obj.get()
        do_something(children)
    except (ConnectionLossException, NoAuthException):
        sys.exit(1)

# 这两个语句立即返回，第二个设置一个回调
# 当 get_children_async 有它的返回值
async_obj = zk.get_children_async("/some/node")
async_obj.rawlink(my_callback)
```

除了返回 `IAsyncResult`对象之外，以下 CRUD 方法的工作方式都与它们的同步对应方法相同。

- 创建方法：`create_async()`
- 检查方法：`exists_async()`、`get_async()`、`get_children_async()`
- 更新方法：`set_async()`
- 删除方法：`delete_async()`

!> 注意： `ensure_path()` 具有目前没有异步版本也不能使用 `delete_async()`方法来执行递归删除。

